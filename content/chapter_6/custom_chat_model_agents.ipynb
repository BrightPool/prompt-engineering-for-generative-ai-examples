{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, BaseSingleActionAgent\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from typing import List, Tuple, Any, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "SERPAPI_API_KEY = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper(serpapi_api_key=SERPAPI_API_KEY)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"LLM\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeAgent(BaseSingleActionAgent):\n",
    "    \"\"\"Fake Custom Agent.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def input_keys(self):\n",
    "        return [\"input\"]\n",
    "\n",
    "    def plan(\n",
    "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        \"\"\"Given input, decided what to do.\n",
    "\n",
    "        Args:\n",
    "            intermediate_steps: Steps the LLM has taken to date,\n",
    "                along with observations\n",
    "            **kwargs: User inputs.\n",
    "\n",
    "        Returns:\n",
    "            Action specifying what tool to use.\n",
    "        \"\"\"\n",
    "        chat = ChatOpenAI()\n",
    "        chat_response = chat([HumanMessage(content=f'''Respond with either 'Yes' or 'No'. \n",
    "                                           Should we use a Google search tool, given the following user query: {kwargs['input']}\n",
    "                                           Only reply with 'Yes' or 'No'.\n",
    "                                           Favor using tools when dates and times are concerned.\n",
    "                                           ''')])\n",
    "        # If yes:\n",
    "        if 'yes'.lower() in chat_response.content.lower():\n",
    "            return AgentAction(tool=\"Search\", tool_input=kwargs[\"input\"], log=\"\")\n",
    "        else:\n",
    "            # Reply in this section with a different tool / LLM to use:\n",
    "            chat_response = chat([HumanMessage(content=f'''Act as an AI assistant and respond effectively to the user's query: {kwargs['input']}''')])\n",
    "            return AgentFinish(return_values={\"output\": chat_response.content}, log=\"\")\n",
    "\n",
    "    async def aplan(\n",
    "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Jane! How can I assist you today?'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = FakeAgent()\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True,\n",
    ")\n",
    "\n",
    "agent_executor.run(\"My name is Jane!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data engineering is a field that focuses on designing and implementing systems to collect, store, and process large amounts of data. It involves various principles and practices to ensure efficient and reliable data management. Here are some key aspects of data engineering principles and practices:\\n\\n1. Data Collection: Data engineers work on establishing mechanisms to collect data from various sources, such as databases, APIs, logs, and sensors. They ensure that data is extracted accurately and in a timely manner.\\n\\n2. Data Storage: Data engineers design storage systems capable of handling large volumes of data. They utilize technologies like databases, data lakes, and data warehouses to store structured, semi-structured, and unstructured data.\\n\\n3. Data Processing: Data engineers develop processes to transform and clean the collected data. This involves activities like data validation, normalization, aggregation, and deduplication. They also employ techniques like data quality checks and data profiling to ensure data integrity.\\n\\n4. Data Integration: Data engineers integrate data from multiple sources to create a unified view. This often requires building Extract, Transform, Load (ETL) pipelines or real-time data streaming pipelines to consolidate and synchronize data.\\n\\n5. Data Governance: Data engineering practices emphasize data governance to maintain data consistency, security, and compliance. Engineers implement access controls, encryption, and data protection measures to safeguard sensitive information.\\n\\n6. Scalability and Performance: Data engineers design systems that can handle increasing data volumes and user demands. They employ distributed computing frameworks, parallel processing, and optimization techniques to ensure scalability and high performance.\\n\\n7. Data Pipeline Monitoring: Engineers monitor data pipelines to detect and resolve issues promptly. They set up alerts, logging, and automated testing to ensure data pipelines are running smoothly and efficiently.\\n\\n8. Data Documentation: Data engineers document data sources, transformations, and processes to enable collaboration and knowledge sharing. This documentation helps maintain data lineage, understand data dependencies, and support troubleshooting.\\n\\nThese principles and practices form the foundation of effective data engineering, enabling organizations to derive valuable insights and make data-driven decisions.'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"Research data engineering principles and practices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, SystemMessage\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which tools the agent can use to answer user queries\n",
    "search = SerpAPIWrapper(serpapi_api_key=SERPAPI_API_KEY)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"\n",
    "Act as a personal assistant, you are tasked with conducting an interview with the user.\n",
    "\n",
    "If you don't need to use a reply, you must follow this response format:\n",
    "\n",
    "Reply: ...A reply to the user...\n",
    "\n",
    "If you need to use a tool, to answer the question, you have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Whenever you need to use a tool, you must follow pattern:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "---\n",
    "\n",
    "To summarize the response formats must either be:\n",
    "- Final Answer: ...\n",
    "- Reply: ...\n",
    "\n",
    "You must always use one of the above response formats!\n",
    "---\n",
    "\n",
    "Previous Chat History:\n",
    "Chat history {chat_history}\n",
    "\n",
    "These were previous tasks you completed:\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool] \n",
    "    memory: Any\n",
    "\n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [SystemMessage(content=formatted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=False, input_key=\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        if \"Reply:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Conversation:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "\n",
    "        # Check if agent should finish\n",
    "        elif \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()\n",
    "llm = ChatOpenAI(temperature=0, model='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"chat_history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools,  memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reply: Nice to meet you, James! How can I assist you today?'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run({\n",
    "    \"input\": \"My name is James\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is James.'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run({\n",
    "    \"input\": \"What is my name?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The average age in the United States is 38.9 years.'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run({\n",
    "    \"input\": \"What is the average age in the US?\",\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
