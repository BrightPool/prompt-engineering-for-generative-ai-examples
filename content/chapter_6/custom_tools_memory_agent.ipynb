{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhYJy91EZrM-"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_openai_tools_agent\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain.tools import StructuredTool\n",
        "from langchain_community.utilities.serpapi import SerpAPIWrapper\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYn7DwugZrNA"
      },
      "outputs": [],
      "source": [
        "# Set the envionrment variable for the API key:\n",
        "os.environ['SERPAPI_API_KEY'] = 'INSERT_API_KEY_HERE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcXgRYTXZrNB"
      },
      "outputs": [],
      "source": [
        "# Define Tools:\n",
        "def google_search(query: str):\n",
        "    \"\"\"Tool to search Google\"\"\"\n",
        "    return SerpAPIWrapper().run(query)\n",
        "\n",
        "def save_interview(raw_interview_text: str):\n",
        "    \"\"\"Tool to save the interview. You must pass the entire interview and conversation in here.\n",
        "    The interview will then be saved to a local file. Remember to include all of the previous chat messages.\n",
        "    Include all of the messages with the user and the AI, here is a good response:\n",
        "    AI: some text\n",
        "    Human: some text\n",
        "    ...\n",
        "    ---\n",
        "    \"\"\"\n",
        "    # Save to local file:\n",
        "    with open(\"interview.txt\", \"w\") as f:\n",
        "        f.write(raw_interview_text)\n",
        "    return f\"Interview saved! Content: {raw_interview_text}. File: interview.txt. You must tell the user that the interview is saved.\"\n",
        "\n",
        "def get_pokemon(pokemon_name: str):\n",
        "    \"\"\"Tool to get a single Pokemon\"\"\"\n",
        "    import requests\n",
        "    clean_pokemon_name = pokemon_name.lower()\n",
        "    # Get the Pokemon\n",
        "    try:\n",
        "        pokemon = requests.get(f\"https://pokeapi.co/api/v2/pokemon/{clean_pokemon_name}\").json()\n",
        "        if pokemon:\n",
        "            return f\"Pokemon found! Name: {pokemon['name']}. Height: {pokemon['height']}. Weight: {pokemon['weight']}.\"\n",
        "        else:\n",
        "            return \"Pokemon not found!\"\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return \"Pokemon not found! Try a different pokemon.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHZcY8UXZrNB"
      },
      "outputs": [],
      "source": [
        "# Convert functions to Structured Tools:\n",
        "google_search = StructuredTool.from_function(google_search)\n",
        "save_interview = StructuredTool.from_function(save_interview)\n",
        "get_single_pokemon = StructuredTool.from_function(get_pokemon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOuGuBcNZrNB"
      },
      "outputs": [],
      "source": [
        "from pydantic.v1 import BaseModel\n",
        "from typing import Optional, Type, Union, Literal, List\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.callbacks.manager import CallbackManagerForToolRun\n",
        "from langchain.tools.base import ToolException\n",
        "from langchain_core.documents import Document\n",
        "import tempfile\n",
        "import requests\n",
        "\n",
        "class ArgumentType(BaseModel):\n",
        "    url: str\n",
        "    file_type: Union[Literal[\"pdf\"], Literal[\"txt\"]]\n",
        "\n",
        "class SummarizeFileFromURL(BaseTool):\n",
        "    name = \"SummarizeFileFromURL\"\n",
        "    description = \"Summarize a file from a URL.\"\n",
        "    args_schema: Type[ArgumentType] = ArgumentType\n",
        "\n",
        "    def _run(\n",
        "        self,\n",
        "        url: str,\n",
        "        file_type: Union[Literal[\"pdf\"], Literal[\"txt\"]],\n",
        "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
        "    ) -> str:\n",
        "        \"\"\"Use the tool.\"\"\"\n",
        "        from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "        from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200:\n",
        "            raise ToolException(\"The URL is not valid. Please try another URL.\")\n",
        "\n",
        "        if file_type == \"pdf\":\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=True) as tmp:\n",
        "                tmp.write(response.content)\n",
        "                pdf_loader = PyPDFLoader(file_path=tmp.name)\n",
        "                documents: List[Document] = pdf_loader.load()\n",
        "\n",
        "        else:\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".txt\", delete=True, mode=\"w+t\") as tmp:\n",
        "                tmp.write(response.text)\n",
        "                text_loader = TextLoader(tmp.name)\n",
        "                documents: List[Document] = text_loader.load()\n",
        "\n",
        "        chain = load_summarize_chain(llm=ChatOpenAI(), chain_type=\"map_reduce\")\n",
        "        return chain.run(documents)\n",
        "\n",
        "    async def _arun(\n",
        "        self,\n",
        "        url: str,\n",
        "        file_type: Union[Literal[\"pdf\"], Literal[\"txt\"]],\n",
        "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
        "    ) -> str:\n",
        "        \"\"\"Use the tool asynchronously.\"\"\"\n",
        "        raise NotImplementedError(\"This tool does not support async yet!\")\n",
        "\n",
        "\n",
        "def _handle_error(error: ToolException) -> str:\n",
        "    return (\n",
        "        \"The following errors occurred during tool execution:\"\n",
        "        + error.args[0]\n",
        "        + \"Please try another tool.\"\n",
        "    )\n",
        "\n",
        "file_summarizer = SummarizeFileFromURL()\n",
        "file_summarizer.handle_tool_error = _handle_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy9jGsTEZrNC"
      },
      "outputs": [],
      "source": [
        "# Tools:\n",
        "tools = [google_search, save_interview, get_single_pokemon, file_summarizer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3W4xSnQZrNC"
      },
      "outputs": [],
      "source": [
        "# Create the llm:\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Create the ChatPromptTemplate:\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# Define the system message:\n",
        "system_message = SystemMessage(\n",
        "    content=\"\"\"Act as a helpful AI interview assistant,\n",
        "               Always ask a follow-up question, especially after returning results.\n",
        "               Ask one question at a time.\n",
        "               Always be in interview mode or tool mode.\n",
        "               Ask the user about the desired topic.\n",
        "               \"\"\"\n",
        ")\n",
        "\n",
        "# Initialize memory:\n",
        "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
        "\n",
        "# Create the Prompt:\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        system_message,\n",
        "        MessagesPlaceholder(variable_name=\"history\"), # This is where the user will write/read their messages from as memory\n",
        "        (\"user\", \"{input}\"),\n",
        "        MessagesPlaceholder(\n",
        "            variable_name=\"agent_scratchpad\"\n",
        "        ),  # This is where the agent will write/read its messages from\n",
        "    ]\n",
        ")\n",
        "\n",
        "agent = create_openai_tools_agent(llm=llm, tools=tools, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhMSoOkjZrNC"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "from operator import itemgetter\n",
        "\n",
        "# Formats the python function tools into JSON schema and binds them to the model:\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "from langchain.agents.format_scratchpad.openai_tools import (\n",
        "    format_to_openai_tool_messages,\n",
        ")\n",
        "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
        "\n",
        "\n",
        "# Setting up the agent chain:\n",
        "agent = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
        "            x[\"intermediate_steps\"]\n",
        "        ),\n",
        "        \"history\": RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm_with_tools\n",
        "    | OpenAIToolsAgentOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OxnPlOUZrNC"
      },
      "outputs": [],
      "source": [
        "# Create an agent executor by passing in the agent, tools and memory:\n",
        "from langchain.agents import AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feqGjRJ-ZrND",
        "outputId": "fa2daf09-709a-4ac4-c81c-5f9472e21b93"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"My name is James, I'm a computer programmer and I like to play cosy games.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqaPehLCZrND",
        "outputId": "0f9eec59-c974-41e1-9b78-94e6f88304c7"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"What is my name and my profession?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwwKQzbdZrND",
        "outputId": "dfb09917-a3a2-4ec3-fcc5-7f05dbc6ec8f"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"Get information about Pikachu\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUCOw0FzZrNE",
        "outputId": "98120ce2-35b8-417b-cadf-363b0d0dfcbc"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"Get information about Charmander\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-S0frDUZrNE",
        "outputId": "840ce901-85b0-4552-e2da-2a0ccfd8317c"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"I want a comprehensive summary of our conversation! Please can you save it?\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ui5ZhGAZrNE",
        "outputId": "05d93481-453f-419a-88f7-03f2f3f22dca"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    agent_executor.invoke({\"input\":\"I want to summarize this https://storage.googleapis.com/oreilly-content/NutriFusion%20Foods%20Marketing%20Plan%202022.docx\"})\n",
        "except Exception as e:\n",
        "    error_message = str(e)\n",
        "    chat = ChatOpenAI()\n",
        "    clean_error_message = chat.invoke([SystemMessage(content=error_message + 'Clean the error message, this will be shown to a user.')])\n",
        "    print(clean_error_message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxlte5msZrNE",
        "outputId": "760e3670-b1d5-4426-ecfe-c630a0c40431"
      },
      "outputs": [],
      "source": [
        "# This line will take several minutes as we are summarizing a 41 page .pdf file:\n",
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"I want to summarize this https://storage.googleapis.com/oreilly-content/pokemon-rules.pdf \"\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
