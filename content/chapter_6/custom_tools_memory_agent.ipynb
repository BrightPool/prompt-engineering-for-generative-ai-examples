{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True\n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.tools import StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "system_message = SystemMessage(content='''Act as a helpful AI interview assistant, \n",
    "                               You will either be having a conversation to generate content or calling a function to help the user.\n",
    "                               \n",
    "                               You must follow the following principles:\n",
    "                               - Always be asking the user a follow up question, especially after returning the results from a previous tool.\n",
    "                               - Ask one question at a time.\n",
    "                               - You must always be in interview mode (asking questions) or in tool mode (calling a function). \n",
    "                               - Ask the user what topic they want to talk about.\n",
    "                               ''')\n",
    "\n",
    "agent_kwargs = {\n",
    "    \"extra_prompt_messages\": [MessagesPlaceholder(variable_name=\"memory\")],\n",
    "    \"system_message\": system_message\n",
    "}\n",
    "memory = ConversationBufferMemory(memory_key=\"memory\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search(query: str):\n",
    "    \"\"\"A google search tool\"\"\"\n",
    "    return f\"Here is a google search result for {query}\"\n",
    "\n",
    "def save_interview(interview_text: str):\n",
    "    \"\"\"A tool to save an interview\"\"\"\n",
    "    return f\"Here is the interview saved: {interview_text}\"\n",
    "\n",
    "def read_pdf_from_url(url: str):\n",
    "    \"\"\"A tool to read a pdf from a url\"\"\"\n",
    "    return f\"Here is the pdf from the url: {url}\"\n",
    "\n",
    "def get_pokemon(pokemon_name: str):\n",
    "    \"\"\"A tool to get a pokemon\"\"\"\n",
    "    return f\"Here is the pokemon: {pokemon_name}\"\n",
    "\n",
    "google_search = StructuredTool.from_function(google_search)\n",
    "save_interview = StructuredTool.from_function(save_interview)\n",
    "read_pdf_from_url = StructuredTool.from_function(read_pdf_from_url)\n",
    "pokemon = StructuredTool.from_function(get_pokemon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"title\": \"google_searchSchemaSchema\", \"type\": \"object\", \"properties\": {\"query\": {\"title\": \"Query\", \"type\": \"string\"}}, \"required\": [\"query\"]}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_search .args_schema.schema_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:tool:google_search] Entering Tool run with input:\n",
      "\u001b[0m\"Data\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:tool:google_search] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Here is a google search result for Data\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a google search result for Data'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_search .run(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "tools = [\n",
    "    google_search,\n",
    "    save_interview,\n",
    "    read_pdf_from_url,\n",
    "    pokemon,\n",
    "]\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True,\n",
    "    memory=memory,\n",
    "    agent_kwargs=agent_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"My name is James, I'm a computer programmer and I like to play cosy games.\",\n",
      "  \"memory\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Act as a helpful AI interview assistant, \\n                               You will either be having a conversation to generate content or calling a function to help the user.\\n                               \\n                               You must follow the following principles:\\n                               - Always be asking the user a follow up question, especially after returning the results from a previous tool.\\n                               - Ask one question at a time.\\n                               - You must always be in interview mode (asking questions) or in tool mode (calling a function). \\n                               - Ask the user what topic they want to talk about.\\n                               \\nHuman: My name is James, I'm a computer programmer and I like to play cosy games.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] [2.60s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Nice to meet you, James! As a computer programmer, I'm sure you have a lot of interesting experiences and insights. And playing cosy games sounds like a great way to relax. Is there anything specific you would like to talk about or any questions you have?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Nice to meet you, James! As a computer programmer, I'm sure you have a lot of interesting experiences and insights. And playing cosy games sounds like a great way to relax. Is there anything specific you would like to talk about or any questions you have?\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 249,\n",
      "      \"completion_tokens\": 54,\n",
      "      \"total_tokens\": 303\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [2.61s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Nice to meet you, James! As a computer programmer, I'm sure you have a lot of interesting experiences and insights. And playing cosy games sounds like a great way to relax. Is there anything specific you would like to talk about or any questions you have?\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, James! As a computer programmer, I'm sure you have a lot of interesting experiences and insights. And playing cosy games sounds like a great way to relax. Is there anything specific you would like to talk about or any questions you have?\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"My name is James, I'm a computer programmer and I like to play cosy games.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Act as a helpful AI interview assistant, \\n                               You will either be having a conversation to generate content or calling a function to help the user.\\n                               \\n                               You must follow the following principles:\\n                               - Always be asking the user a follow up question, especially after returning the results from a previous tool.\\n                               - Ask one question at a time.\\n                               - You must always be in interview mode (asking questions) or in tool mode (calling a function). \\n                               - Ask the user what topic they want to talk about.\\n                               \\nHuman: My name is James, I'm a computer programmer and I like to play cosy games.\\nAI: Nice to meet you, James! As a computer programmer, I'm sure you have a lot of interesting experiences and insights. And playing cosy games sounds like a great way to relax. Is there anything specific you would like to talk about or any questions you have?\\nHuman: What is my name and my profession?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] [1.45s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Your name is James and you mentioned that you are a computer programmer. Is there anything specific you would like to discuss related to programming or cosy games?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Your name is James and you mentioned that you are a computer programmer. Is there anything specific you would like to discuss related to programming or cosy games?\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 318,\n",
      "      \"completion_tokens\": 31,\n",
      "      \"total_tokens\": 349\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [1.45s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Your name is James and you mentioned that you are a computer programmer. Is there anything specific you would like to discuss related to programming or cosy games?\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is James and you mentioned that you are a computer programmer. Is there anything specific you would like to discuss related to programming or cosy games?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('What is my name and my profession?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
