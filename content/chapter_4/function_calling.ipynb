{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "def schedule_meeting(date, time, attendees):\n",
    "    # Connect to calendar service:\n",
    "    return { \"event_id\": \"1234\", \"status\": \"Meeting scheduled successfully!\",\n",
    "            \"date\": date, \"time\": time, \"attendees\": attendees }\n",
    "\n",
    "OPENAI_FUNCTIONS = {\n",
    "    \"schedule_meeting\": schedule_meeting\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our predefined function JSON schema:\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"schedule_meeting\",\n",
    "        \"description\": \"Set a meeting at a specified date and time for designated attendees\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"date\": {\"type\": \"string\", \"format\": \"date\"},\n",
    "                \"time\": {\"type\": \"string\", \"format\": \"time\"},\n",
    "                \"attendees\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "            },\n",
    "            \"required\": [\"date\", \"time\", \"attendees\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the function arguments:  {'date': '2023-11-01', 'time': '14:00', 'attendees': ['Alice', 'Bob']}\n",
      "This is the function name:  schedule_meeting\n",
      "Meeting scheduled successfully! \n",
      "- Date: 2023-11-01 \n",
      "- Time: 14:00 \n",
      "- Attendees: Alice, Bob \n",
      "- Event ID: 1234\n"
     ]
    }
   ],
   "source": [
    "# Start the conversation:\n",
    "messages = [{\"role\": \"user\", \"content\": \"Schedule a meeting on 2023-11-01 at 14:00 with Alice and Bob.\"}]\n",
    "\n",
    "# Send the conversation and function schema to the model:\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\"\n",
    ")\n",
    "\n",
    "response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "# Check if the model wants to call our function:\n",
    "if response_message.get(\"function_call\"):\n",
    "    # Extract the arguments:\n",
    "    function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "    print(\"These are the function arguments: \", function_args)\n",
    "\n",
    "    # Find the function to call:\n",
    "    function_name = response_message[\"function_call\"][\"name\"]\n",
    "    print(\"This is the function name: \", function_name)\n",
    "    function = OPENAI_FUNCTIONS.get(function_name)\n",
    "\n",
    "    if not function:\n",
    "        raise Exception(f\"Function {function_name} not found.\")\n",
    "\n",
    "    # Call the function:\n",
    "    function_response = function(**function_args)\n",
    "\n",
    "    # Share the function's response with the model:\n",
    "    messages.append({\n",
    "        \"role\": \"function\",\n",
    "        \"name\": \"schedule_meeting\",\n",
    "        \"content\": json.dumps(function_response)\n",
    "    })\n",
    "\n",
    "    # Let the model generate a user-friendly response:\n",
    "    second_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    print(second_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Extracting Data with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a proficient algorithm capable of extracting structured information.\n",
      "Human: *Extract* key points and any contrarian positions from the provided input using the specified format: In the recent article titled 'AI adoption in industry', key points addressed include the growing interest in AI in various sectors, the increase in AI research, and the need for responsible AI. However, the author, Dr. Jane Smith, acknowledges a contrarian view — that without stringent regulations, AI may pose high risks. The anonymity of AI decision-making and the potential for misuse were stressed.\n",
      "Human: *Remember to* produce your answer in the correct format\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Article(points='The growing interest in AI in various sectors, the increase in AI research, and the need for responsible AI.', contrarian_points='Without stringent regulations, AI may pose high risks. The anonymity of AI decision-making and the potential for misuse were stressed.', author='Dr. Jane Smith')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Article(BaseModel):\n",
    "    \"\"\"Identifying key points and contrarian views in an article.\"\"\"\n",
    "\n",
    "    points: str = Field(..., description=\"Key points from the article\")\n",
    "    contrarian_points: Optional[str] = Field(None, description=\"Any contrarian points acknowledged in the article\")\n",
    "    author: Optional[str] = Field(None, description=\"Author of the article\")\n",
    "\n",
    "# If we pass in a model explicitly, we need to make sure it supports the OpenAI function-calling API.\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a proficient algorithm capable of extracting structured information.\"),\n",
    "        (\"human\", \"*Extract* key points and any contrarian positions from the provided input using the specified format: {input}\"),\n",
    "        (\"human\", \"*Remember to* produce your answer in the correct format\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = create_structured_output_chain(Article, llm, prompt, verbose=True)\n",
    "chain.run(\"In the recent article titled 'AI adoption in industry', key points addressed include the growing interest in AI in various sectors, the increase in AI research, and the need for responsible AI. However, the author, Dr. Jane Smith, acknowledges a contrarian view — that without stringent regulations, AI may pose high risks. The anonymity of AI decision-making and the potential for misuse were stressed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
