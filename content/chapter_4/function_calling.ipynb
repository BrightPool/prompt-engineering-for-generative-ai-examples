{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Function Calling with Tool Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from os import getenv\n",
    "\n",
    "client = OpenAI(api_key=getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def schedule_meeting(date, time, attendees):\n",
    "    # Connect to calendar service:\n",
    "    return { \"event_id\": \"1234\", \"status\": \"Meeting scheduled successfully!\",\n",
    "            \"date\": date, \"time\": time, \"attendees\": attendees }\n",
    "\n",
    "OPENAI_FUNCTIONS = {\n",
    "    \"schedule_meeting\": schedule_meeting\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our predefined function JSON schema:\n",
    "functions = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"type\": \"object\",\n",
    "            \"name\": \"schedule_meeting\",\n",
    "            \"description\": \"Set a meeting at a specified date and time for designated attendees\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"date\": {\"type\": \"string\", \"format\": \"date\"},\n",
    "                    \"time\": {\"type\": \"string\", \"format\": \"time\"},\n",
    "                    \"attendees\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "                },\n",
    "                \"required\": [\"date\", \"time\", \"attendees\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the function name:  schedule_meeting\n",
      "These are the function arguments:  {'date': '2023-11-01', 'time': '14:00', 'attendees': ['Alice', 'Bob']}\n",
      "I have scheduled a meeting with Alice and Bob on November 1, 2023, at 14:00. The event ID is 1234.\n"
     ]
    }
   ],
   "source": [
    "# Start the conversation:\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Schedule a meeting on 2023-11-01 at 14:00 with Alice and Bob.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Send the conversation and function schema to the model:\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=messages,\n",
    "    tools=functions,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "response = response.choices[0].message\n",
    "\n",
    "# Check if the model wants to call our function:\n",
    "if response.tool_calls:\n",
    "    # Get the first function call:\n",
    "    first_tool_call = response.tool_calls[0]\n",
    "\n",
    "    # Find the function name and function args to call:\n",
    "    function_name = first_tool_call.function.name\n",
    "    function_args = json.loads(first_tool_call.function.arguments)\n",
    "    print(\"This is the function name: \", function_name)\n",
    "    print(\"These are the function arguments: \", function_args)\n",
    "\n",
    "    function = OPENAI_FUNCTIONS.get(function_name)\n",
    "\n",
    "    if not function:\n",
    "        raise Exception(f\"Function {function_name} not found.\")\n",
    "\n",
    "    # Call the function:\n",
    "    function_response = function(**function_args)\n",
    "\n",
    "    # Share the function's response with the model:\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"schedule_meeting\",\n",
    "            \"content\": json.dumps(function_response),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Let the model generate a user-friendly response:\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\", messages=messages\n",
    "    )\n",
    "\n",
    "    print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Function Calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the function name:  schedule_meeting\n",
      "These are the function arguments:  {'date': '2023-11-01', 'time': '14:00', 'attendees': ['Alice', 'Bob']}\n",
      "This is the function name:  schedule_meeting\n",
      "These are the function arguments:  {'date': '2023-11-02', 'time': '15:00', 'attendees': ['Charlie', 'Dave']}\n",
      "Two meetings have been scheduled:\n",
      "1. Meeting with Alice and Bob on 2023-11-01 at 14:00.\n",
      "2. Meeting with Charlie and Dave on 2023-11-02 at 15:00.\n"
     ]
    }
   ],
   "source": [
    "# Start the conversation:\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": '''Schedule a meeting on 2023-11-01 at 14:00 with Alice and Bob. \n",
    "        Then I want to schedule another meeting on 2023-11-02 at 15:00 with Charlie and Dave.'''\n",
    "    }\n",
    "]\n",
    "\n",
    "# Send the conversation and function schema to the model:\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=messages,\n",
    "    tools=functions,\n",
    ")\n",
    "\n",
    "response = response.choices[0].message\n",
    "\n",
    "# Check if the model wants to call our function:\n",
    "if response.tool_calls:\n",
    "    for tool_call in response.tool_calls:\n",
    "        # Get the function name and arguments to call:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        print(\"This is the function name: \", function_name)\n",
    "        print(\"These are the function arguments: \", function_args)\n",
    "\n",
    "        function = OPENAI_FUNCTIONS.get(function_name)\n",
    "\n",
    "        if not function:\n",
    "            raise Exception(f\"Function {function_name} not found.\")\n",
    "\n",
    "        # Call the function:\n",
    "        function_response = function(**function_args)\n",
    "\n",
    "        # Share the function's response with the model:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": json.dumps(function_response),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Let the model generate a user-friendly response:\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\", messages=messages\n",
    "    )\n",
    "\n",
    "    print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Extracting Data with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a proficient algorithm capable of extracting structured information.\n",
      "Human: *Extract* key points and any contrarian positions from the provided input using the specified format: In the recent article titled 'AI adoption in industry', key points addressed include the growing interest in AI in various sectors, the increase in AI research, and the need for responsible AI. However, the author, Dr. Jane Smith, acknowledges a contrarian view â€” that without stringent regulations, AI may pose high risks. The anonymity of AI decision-making and the potential for misuse were stressed.\n",
      "Human: *Remember to* produce your answer in the correct format\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Article(points='The growing interest in AI in various sectors, the increase in AI research, and the need for responsible AI.', contrarian_points='Without stringent regulations, AI may pose high risks. The anonymity of AI decision-making and the potential for misuse were stressed.', author='Dr. Jane Smith')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Article(BaseModel):\n",
    "    \"\"\"Identifying key points and contrarian views in an article.\"\"\"\n",
    "\n",
    "    points: str = Field(..., description=\"Key points from the article\")\n",
    "    contrarian_points: Optional[str] = Field(None, description=\"Any contrarian points acknowledged in the article\")\n",
    "    author: Optional[str] = Field(None, description=\"Author of the article\")\n",
    "\n",
    "# If we pass in a model explicitly, we need to make sure it supports the OpenAI function-calling API.\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a proficient algorithm capable of extracting structured information.\"),\n",
    "        (\"human\", \"*Extract* key points and any contrarian positions from the provided input using the specified format: {input}\"),\n",
    "        (\"human\", \"*Remember to* produce your answer in the correct format\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = create_structured_output_chain(Article, llm, prompt, verbose=True)\n",
    "chain.run(\"In the recent article titled 'AI adoption in industry', key points addressed include the growing interest in AI in various sectors, the increase in AI research, and the need for responsible AI. However, the author, Dr. Jane Smith, acknowledges a contrarian view â€” that without stringent regulations, AI may pose high risks. The anonymity of AI decision-making and the potential for misuse were stressed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
