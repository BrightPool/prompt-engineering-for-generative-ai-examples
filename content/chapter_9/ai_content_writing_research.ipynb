{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.document_loaders import AsyncHtmlLoader, AsyncChromiumLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from serpapi import GoogleSearch\n",
    "import os\n",
    "from typing import Dict, List, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nest_asyncio --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Research:\n",
    "\n",
    "Use a browsing agent to search for the top 3 posts on a topic and summarize them. Progressive summarization and agent tool use.\n",
    "\n",
    "- https://python.langchain.com/docs/use_cases/web_scraping/#loader\n",
    "- https://python.langchain.com/docs/modules/data_connection/retrievers/web_research - Not viable for production, because it is only question based answering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-search-results --quiet\n",
    "%pip install html2text --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest-playwright in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (0.4.2)\n",
      "Requirement already satisfied: playwright>=1.18 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest-playwright) (1.37.0)\n",
      "Requirement already satisfied: pytest<8.0.0,>=6.2.4 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest-playwright) (7.1.2)\n",
      "Requirement already satisfied: python-slugify<9.0.0,>=6.0.0 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest-playwright) (8.0.1)\n",
      "Requirement already satisfied: pytest-base-url<3.0.0,>=1.0.0 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest-playwright) (2.0.0)\n",
      "Requirement already satisfied: greenlet==2.0.2 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from playwright>=1.18->pytest-playwright) (2.0.2)\n",
      "Requirement already satisfied: pyee==9.0.4 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from playwright>=1.18->pytest-playwright) (9.0.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pyee==9.0.4->playwright>=1.18->pytest-playwright) (4.5.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (21.4.0)\n",
      "Requirement already satisfied: iniconfig in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (1.1.1)\n",
      "Requirement already satisfied: packaging in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (21.3)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (1.11.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.9 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.28.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from python-slugify<9.0.0,>=6.0.0->pytest-playwright) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2022.9.24)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from packaging->pytest<8.0.0,>=6.2.4->pytest-playwright) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing Playwright:\n",
    "%pip install pytest-playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = \"Neural networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SERPAPI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM + text splitter:\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1500, chunk_overlap=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearch(\n",
    "    {\n",
    "        \"q\": TOPIC,\n",
    "        \"location\": \"Austin,Texas\",\n",
    "        \"api_key\": os.environ[\"SERPAPI_API_KEY\"],\n",
    "    }\n",
    ")\n",
    "# Get the results:\n",
    "result = search.get_dict()\n",
    "\n",
    "# Put the results in a Pandas DataFrame:\n",
    "serp_results = pd.DataFrame(result[\"organic_results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_content_from_urls(\n",
    "    df: pd.DataFrame, number_of_urls: int = 3, url_column: str = \"link\"\n",
    ") -> List[Document]:\n",
    "    # Get the HTML content of the first 3 URLs:\n",
    "    urls = df[url_column].values[:number_of_urls].tolist()\n",
    "    # If there is only one URL, convert it to a list:\n",
    "    if isinstance(urls, str):\n",
    "        urls = [urls]\n",
    "    # Check for empty URLs:\n",
    "    urls = [url for url in urls if url != \"\"]\n",
    "\n",
    "    # Check for duplicate URLs:\n",
    "    urls = list(set(urls))\n",
    "\n",
    "    # Throw error if no URLs are found:\n",
    "    if len(urls) == 0:\n",
    "        raise ValueError(\"No URLs found!\")\n",
    "    # loader = AsyncHtmlLoader(urls) # Faster but might not always work.\n",
    "    loader = AsyncChromiumLoader(urls)\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_webpages(documents: List[Document]):\n",
    "    html2text = Html2TextTransformer()\n",
    "    return html2text.transform_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentSummary(BaseModel):\n",
    "    concise_summary: str\n",
    "    writing_style: str\n",
    "    key_points: List[str]\n",
    "    expert_opinions: Optional[List[str]] = None\n",
    "    metadata: Dict[\n",
    "        str, str\n",
    "    ] = None  # This comes natively from the LangChain document loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def create_summary_from_text(\n",
    "    document: Document, parser: PydanticOutputParser\n",
    ") -> Union[DocumentSummary, None]:\n",
    "    # Split the parent document into chunks:\n",
    "    split_docs = text_splitter.split_documents([document])\n",
    "\n",
    "    # If there are no documents, return None:\n",
    "    if len(split_docs) == 0:\n",
    "        return None\n",
    "\n",
    "    # Run a refine summarization chain that extracts unique key points and opinions within an article:\n",
    "    prompt_template = \"\"\"Act as a content SEO researcher. You are interested in summarizing and extracting key points from the following text. \n",
    "    The insights gained will be used to do content research and we will compare the key points, insights and summaries across multiple articles.\n",
    "    ---\n",
    "    - You must analyze the text and extract the key points and opinions from the following text\n",
    "    - You must extract the key points and opinions from the following text:\n",
    "    {text}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # Refine template:\n",
    "    refine_template = (\n",
    "        \"Your job is to produce a final summary.\\n\"\n",
    "        \"We have provided an existing summary, key points, and expert opinions up to a certain point: {existing_answer}\\n\"\n",
    "        \"We have the opportunity to refine the existing content (only if needed) with some more context below.\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"{text}\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"Given the new context, refine the original summary.\\n\"\n",
    "        \"If the context isn't useful or does not provide additional key points or expert opinions, you must return the original summary.\"\n",
    "        \"{format_instructions}\"\n",
    "    )\n",
    "    refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "\n",
    "    chain = load_summarize_chain(\n",
    "        llm=llm,\n",
    "        chain_type=\"refine\",\n",
    "        question_prompt=prompt,\n",
    "        refine_prompt=refine_prompt,\n",
    "        return_intermediate_steps=True,\n",
    "        input_key=\"input_documents\",\n",
    "        output_key=\"output_text\",\n",
    "    )\n",
    "\n",
    "    print('Summarizing the data!')\n",
    "    summary_result = await chain._acall(inputs=\n",
    "        {\n",
    "            \"input_documents\": split_docs,\n",
    "            \"format_instructions\": parser.get_format_instructions(),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"Parsing the output!\")\n",
    "    document_summary = parser.parse(summary_result[\"output_text\"])\n",
    "    print(\"Parsed the output!\")\n",
    "\n",
    "    document_summary.metadata = document.metadata\n",
    "    return document_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=DocumentSummary)\n",
    "\n",
    "# Extract the html content from the URLs:\n",
    "html_documents = get_html_content_from_urls(serp_results)\n",
    "\n",
    "# Extract the text from the URLs:\n",
    "text_documents = extract_text_from_webpages(html_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_all_summaries(text_documents, parser):\n",
    "    # Create an array of coroutines\n",
    "    tasks = [create_summary_from_text(document, parser) for document in text_documents]\n",
    "    \n",
    "    # Execute the tasks concurrently and gather all the results\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # Filter out None values\n",
    "    summaries = [summary for summary in results if summary is not None]\n",
    "    \n",
    "    if len(summaries) == 0:\n",
    "        raise ValueError(\"No summaries were created!\")\n",
    "    \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing the data!\n",
      "Summarizing the data!\n",
      "Summarizing the data!\n",
      "Parsing the output!\n",
      "Parsed the output!\n",
      "Parsing the output!\n",
      "Parsed the output!\n",
      "Parsing the output!\n",
      "Parsed the output!\n"
     ]
    }
   ],
   "source": [
    "summaries = await create_all_summaries(text_documents, parser)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Expert Interview Questions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promising agents:\n",
    "- https://python.langchain.com/docs/modules/agents/\n",
    "- https://python.langchain.com/docs/modules/agents/agent_types/structured_chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import OpenAIFunctionsAgent, OpenAIMultiFunctionsAgent\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom tools:\n",
    "from tools.generate_interview_questions import GenerateInterviewQuestions\n",
    "from tools.human_in_the_loop import HumanInTheLoop\n",
    "from tools.load_json import LoadJsonFile\n",
    "from tools.save_json import SaveJsonFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model='gpt-4')\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Generate tools:\n",
    "tools = [GenerateInterviewQuestions(), HumanInTheLoop(), LoadJsonFile(), SaveJsonFile()]\n",
    "\n",
    "system_message = SystemMessage(content=f'''You are very powerful assistant and are responsible for investigating the following topic: {TOPIC}. \n",
    "                               You are bad at extracting key points from articles and need help.\n",
    "                               Also you must let the human answer questions as this is their interview.\n",
    "                               ---\n",
    "                               ''')\n",
    "\n",
    "# Generate memory:\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "memory = ConversationBufferMemory(memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message, extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)])\n",
    "\n",
    "# Create the agent:\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Create the agent executor:\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the agent executor!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting the agent executor!\")\n",
    "agent_executor.memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"My name is James, what is your name?\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are very powerful assistant and are responsible for investigating the following topic: Neural networks. \\n                               You are bad at extracting key points from articles and need help.\\n                               Also you must let the human answer questions as this is their interview.\\n                               ---\\n                               \\nHuman: My name is James, what is your name?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] [3.57s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Hello James, I'm OpenAI's language model. I don't have a personal name as I'm an artificial intelligence. How can I assist you today?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Hello James, I'm OpenAI's language model. I don't have a personal name as I'm an artificial intelligence. How can I assist you today?\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 244,\n",
      "      \"completion_tokens\": 33,\n",
      "      \"total_tokens\": 277\n",
      "    },\n",
      "    \"model_name\": \"gpt-4\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [3.57s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Hello James, I'm OpenAI's language model. I don't have a personal name as I'm an artificial intelligence. How can I assist you today?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor.run(f\"My name is James, what is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are very powerful assistant and are responsible for investigating the following topic: Neural networks. \\n                               You are bad at extracting key points from articles and need help.\\n                               Also you must let the human answer questions as this is their interview.\\n                               ---\\n                               \\nHuman: My name is James, what is your name?\\nAI: Hello James, I'm OpenAI's language model. I don't have a personal name as I'm an artificial intelligence. How can I assist you today?\\nHuman: What is my name?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] [1.14s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Your name is James.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Your name is James.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 289,\n",
      "      \"completion_tokens\": 6,\n",
      "      \"total_tokens\": 295\n",
      "    },\n",
      "    \"model_name\": \"gpt-4\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [1.14s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Your name is James.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is James.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(f\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are very powerful assistant and are responsible for investigating the following topic: Neural networks. \\n                               You are bad at extracting key points from articles and need help.\\n                               Also you must let the human answer questions as this is their interview.\\n                               ---\\n                               \\nHuman: My name is James, what is your name?\\nAI: Hello James, I'm OpenAI's language model. I don't have a personal name as I'm an artificial intelligence. How can I assist you today?\\nHuman: What is my name?\\nAI: Your name is James.\\nHuman: Here is some useful information for later on:\\n                   document_summaries: [{'concise_summary': 'Neural network theory helps understand how neurons in the brain function and create artificial intelligence. The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James. Artificial neural networks are used for solving AI problems and can derive conclusions from complex information. The history of neural networks includes the development of computational models and the discovery of Hebbian learning. The backpropagation algorithm and the increase in computer processing power have further advanced neural network research. Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'writing_style': 'The text provides a historical overview of neural network theory and its applications in artificial intelligence. It highlights the development of computational models, the discovery of Hebbian learning, and the advancements enabled by the backpropagation algorithm and increased computer processing power. The writing style is informative and objective.', 'key_points': ['Neural network theory helps understand how neurons in the brain function and create artificial intelligence.', 'The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James.', 'Artificial neural networks are used for solving AI problems and can derive conclusions from complex information.', 'The history of neural networks includes the development of computational models and the discovery of Hebbian learning.', 'The backpropagation algorithm and the increase in computer processing power have further advanced neural network research.', 'Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'Recent emphasis on the explainability of AI has contributed towards the development of methods for visualizing and explaining learned neural networks.', 'Researchers are uncovering generic principles that allow a learning machine to be successful.', 'Hybrid models combining neural networks and symbolic approaches are advocated by some researchers.', 'The role of neuromodulators such as dopamine, acetylcholine, and serotonin on behavior and learning is being explored.', 'Biophysical models and computational algorithms used in the brain are being studied.', 'Computational devices for neuromorphic computing and nanodevices for neural computing are being developed.', 'Recurrent neural networks and deep feedforward neural networks have achieved success in pattern recognition and machine learning competitions.', 'Variants of the backpropagation algorithm and unsupervised methods are used to train deep, highly nonlinear neural architectures.', 'Radial basis function and wavelet networks offer best approximation properties and have applications in nonlinear system identification and classification.', 'Analytical and computational techniques derived from statistical physics can be applied to analyze the weight space of deep neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://en.wikipedia.org/wiki/Neural_network'}}, {'concise_summary': 'Deep learning is a technique in artificial intelligence that has been around for over 70 years. It involves neural networks, which were first proposed in 1944. Neural networks fell out of favor in the late 1960s but experienced a resurgence in the 1980s and again in the 2000s. Deep learning has become popular in recent years due to increased processing power. Neural nets are a form of machine learning, where a computer learns to perform tasks by analyzing training examples.', 'writing_style': 'Informative', 'key_points': ['Deep learning is a new name for neural networks, which have been around for over 70 years.', 'Neural networks were first proposed in 1944 and experienced periods of popularity and decline.', 'Deep learning has become popular again in recent years due to increased processing power.', 'Neural nets are a form of machine learning, where a computer learns from training examples.', 'Neural nets consist of interconnected processing nodes and are organized into layers.', 'During training, the weights and thresholds of neural nets are adjusted to yield consistent outputs.', 'Neural nets have been used in neuroscientific research to understand how the brain processes information.', 'The Perceptron, a trainable neural network, was demonstrated in 1957.', 'Neural nets faced limitations in the past, but algorithms developed in the 1980s removed many of these limitations.', 'The recent resurgence in neural networks is attributed to the development of graphics processing units (GPUs).', 'Deep learning, characterized by the depth of network layers, is responsible for the best-performing AI systems.', 'There is ongoing research to understand the analytic strategies adopted by neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414'}}, {'concise_summary': \\\"Neural networks are a subset of machine learning and are at the heart of deep learning algorithms. They mimic the way biological neurons signal to one another. Neural networks rely on training data to improve their accuracy over time and are powerful tools in computer science and artificial intelligence. They can classify and cluster data quickly, such as in speech recognition or image recognition tasks. Google's search algorithm is a well-known neural network.\\\", 'writing_style': 'The text provides a clear explanation of neural networks and their structure. It uses examples and equations to illustrate how neural networks work.', 'key_points': ['Neural networks are inspired by the human brain and mimic the way neurons signal to one another.', 'They consist of node layers, including an input layer, hidden layers, and an output layer.', 'Each node has an associated weight and threshold, and if the output exceeds the threshold, the node is activated.', 'Neural networks rely on training data to improve their accuracy over time.', 'They are powerful tools in computer science and artificial intelligence, allowing for quick classification and clustering of data.', \\\"Google's search algorithm is a well-known neural network.\\\", 'Neural networks leverage sigmoid neurons, which have values between 0 and 1, and this reduces the impact of changes in variables on the output.', 'Supervised learning and cost functions, such as mean squared error, are used to train neural networks.', 'Gradient descent and backpropagation are techniques used to adjust the weights and minimize the cost function.', 'Different types of neural networks include feedforward neural networks, convolutional neural networks, and recurrent neural networks.', 'Deep learning refers to neural networks with more than three layers, while basic neural networks have two or three layers.', 'The history of neural networks dates back to the 1940s and includes key milestones such as the development of the perceptron and the concept of backpropagation.', 'In 1943, Warren S. McCulloch and Walter Pitts published a research paper that compared neurons to a binary threshold and laid the foundation for neural networks.', \\\"Frank Rosenblatt's development of the perceptron in 1958 introduced weights to neural networks and enabled computers to learn and distinguish patterns.\\\", 'Paul Werbos noted the application of backpropagation in neural networks in 1974, contributing to the advancement of the field.', \\\"Yann LeCun's research in 1989 demonstrated the successful use of neural networks to recognize hand-written zip code digits.\\\", 'Neural networks are used in various applications, including speech recognition and image recognition tasks.'], 'expert_opinions': [], 'metadata': {'source': 'https://www.ibm.com/topics/neural-networks'}}]\\n                   topic: Neural networks\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] [252.88s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"function_call\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"generate_interview_questions\",\n",
      "                \"arguments\": \"{\\n\\\"document_summaries\\\": \\\"[{'concise_summary': 'Neural network theory helps understand how neurons in the brain function and create artificial intelligence. The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James. Artificial neural networks are used for solving AI problems and can derive conclusions from complex information. The history of neural networks includes the development of computational models and the discovery of Hebbian learning. The backpropagation algorithm and the increase in computer processing power have further advanced neural network research. Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'writing_style': 'The text provides a historical overview of neural network theory and its applications in artificial intelligence. It highlights the development of computational models, the discovery of Hebbian learning, and the advancements enabled by the backpropagation algorithm and increased computer processing power. The writing style is informative and objective.', 'key_points': ['Neural network theory helps understand how neurons in the brain function and create artificial intelligence.', 'The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James.', 'Artificial neural networks are used for solving AI problems and can derive conclusions from complex information.', 'The history of neural networks includes the development of computational models and the discovery of Hebbian learning.', 'The backpropagation algorithm and the increase in computer processing power have further advanced neural network research.', 'Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'Recent emphasis on the explainability of AI has contributed towards the development of methods for visualizing and explaining learned neural networks.', 'Researchers are uncovering generic principles that allow a learning machine to be successful.', 'Hybrid models combining neural networks and symbolic approaches are advocated by some researchers.', 'The role of neuromodulators such as dopamine, acetylcholine, and serotonin on behavior and learning is being explored.', 'Biophysical models and computational algorithms used in the brain are being studied.', 'Computational devices for neuromorphic computing and nanodevices for neural computing are being developed.', 'Recurrent neural networks and deep feedforward neural networks have achieved success in pattern recognition and machine learning competitions.', 'Variants of the backpropagation algorithm and unsupervised methods are used to train deep, highly nonlinear neural architectures.', 'Radial basis function and wavelet networks offer best approximation properties and have applications in nonlinear system identification and classification.', 'Analytical and computational techniques derived from statistical physics can be applied to analyze the weight space of deep neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://en.wikipedia.org/wiki/Neural_network'}}, {'concise_summary': 'Deep learning is a technique in artificial intelligence that has been around for over 70 years. It involves neural networks, which were first proposed in 1944. Neural networks fell out of favor in the late 1960s but experienced a resurgence in the 1980s and again in the 2000s. Deep learning has become popular in recent years due to increased processing power. Neural nets are a form of machine learning, where a computer learns to perform tasks by analyzing training examples.', 'writing_style': 'Informative', 'key_points': ['Deep learning is a new name for neural networks, which have been around for over 70 years.', 'Neural networks were first proposed in 1944 and experienced periods of popularity and decline.', 'Deep learning has become popular again in recent years due to increased processing power.', 'Neural nets are a form of machine learning, where a computer learns from training examples.', 'Neural nets consist of interconnected processing nodes and are organized into layers.', 'During training, the weights and thresholds of neural nets are adjusted to yield consistent outputs.', 'Neural nets have been used in neuroscientific research to understand how the brain processes information.', 'The Perceptron, a trainable neural network, was demonstrated in 1957.', 'Neural nets faced limitations in the past, but algorithms developed in the 1980s removed many of these limitations.', 'The recent resurgence in neural networks is attributed to the development of graphics processing units (GPUs).', 'Deep learning, characterized by the depth of network layers, is responsible for the best-performing AI systems.', 'There is ongoing research to understand the analytic strategies adopted by neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414'}}, {'concise_summary': 'Neural networks are a subset of machine learning and are at the heart of deep learning algorithms. They mimic the way biological neurons signal to one another. Neural networks rely on training data to improve their accuracy over time and are powerful tools in computer science and artificial intelligence. They can classify and cluster data quickly, such as in speech recognition or image recognition tasks. Google's search algorithm is a well-known neural network.', 'writing_style': 'The text provides a clear explanation of neural networks and their structure. It uses examples and equations to illustrate how neural networks work.', 'key_points': ['Neural networks are inspired by the human brain and mimic the way neurons signal to one another.', 'They consist of node layers, including an input layer, hidden layers, and an output layer.', 'Each node has an associated weight and threshold, and if the output exceeds the threshold, the node is activated.', 'Neural networks rely on training data to improve their accuracy over time.', 'They are powerful tools in computer science and artificial intelligence, allowing for quick classification and clustering of data.', 'Google's search algorithm is a well-known neural network.', 'Neural networks leverage sigmoid neurons, which have values between 0 and 1, and this reduces the impact of changes in variables on the output.', 'Supervised learning and cost functions, such as mean squared error, are used to train neural networks.', 'Gradient descent and backpropagation are techniques used to adjust the weights and minimize the cost function.', 'Different types of neural networks include feedforward neural networks, convolutional neural networks, and recurrent neural networks.', 'Deep learning refers to neural networks with more than three layers, while basic neural networks have two or three layers.', 'The history of neural networks dates back to the 1940s and includes key milestones such as the development of the perceptron and the concept of backpropagation.', 'In 1943, Warren S. McCulloch and Walter Pitts published a research paper that compared neurons to a binary threshold and laid the foundation for neural networks.', 'Frank Rosenblatt's development of the perceptron in 1958 introduced weights to neural networks and enabled computers to learn and distinguish patterns.', 'Paul Werbos noted the application of backpropagation in neural networks in 1974, contributing to the advancement of the field.', 'Yann LeCun's research in 1989 demonstrated the successful use of neural networks to recognize hand-written zip code digits.', 'Neural networks are used in various applications, including speech recognition and image recognition tasks.'], 'expert_opinions': [], 'metadata': {'source': 'https://www.ibm.com/topics/neural-networks'}}]\\\",\\n\\\"topic\\\": \\\"Neural networks\\\"\\n}\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1780,\n",
      "      \"completion_tokens\": 1481,\n",
      "      \"total_tokens\": 3261\n",
      "    },\n",
      "    \"model_name\": \"gpt-4\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 3:tool:generate_interview_questions] Entering Tool run with input:\n",
      "\u001b[0m\"{'document_summaries': \"[{'concise_summary': 'Neural network theory helps understand how neurons in the brain function and create artificial intelligence. The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James. Artificial neural networks are used for solving AI problems and can derive conclusions from complex information. The history of neural networks includes the development of computational models and the discovery of Hebbian learning. The backpropagation algorithm and the increase in computer processing power have further advanced neural network research. Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'writing_style': 'The text provides a historical overview of neural network theory and its applications in artificial intelligence. It highlights the development of computational models, the discovery of Hebbian learning, and the advancements enabled by the backpropagation algorithm and increased computer processing power. The writing style is informative and objective.', 'key_points': ['Neural network theory helps understand how neurons in the brain function and create artificial intelligence.', 'The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James.', 'Artificial neural networks are used for solving AI problems and can derive conclusions from complex information.', 'The history of neural networks includes the development of computational models and the discovery of Hebbian learning.', 'The backpropagation algorithm and the increase in computer processing power have further advanced neural network research.', 'Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'Recent emphasis on the explainability of AI has contributed towards the development of methods for visualizing and explaining learned neural networks.', 'Researchers are uncovering generic principles that allow a learning machine to be successful.', 'Hybrid models combining neural networks and symbolic approaches are advocated by some researchers.', 'The role of neuromodulators such as dopamine, acetylcholine, and serotonin on behavior and learning is being explored.', 'Biophysical models and computational algorithms used in the brain are being studied.', 'Computational devices for neuromorphic computing and nanodevices for neural computing are being developed.', 'Recurrent neural networks and deep feedforward neural networks have achieved success in pattern recognition and machine learning competitions.', 'Variants of the backpropagation algorithm and unsupervised methods are used to train deep, highly nonlinear neural architectures.', 'Radial basis function and wavelet networks offer best approximation properties and have applications in nonlinear system identification and classification.', 'Analytical and computational techniques derived from statistical physics can be applied to analyze the weight space of deep neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://en.wikipedia.org/wiki/Neural_network'}}, {'concise_summary': 'Deep learning is a technique in artificial intelligence that has been around for over 70 years. It involves neural networks, which were first proposed in 1944. Neural networks fell out of favor in the late 1960s but experienced a resurgence in the 1980s and again in the 2000s. Deep learning has become popular in recent years due to increased processing power. Neural nets are a form of machine learning, where a computer learns to perform tasks by analyzing training examples.', 'writing_style': 'Informative', 'key_points': ['Deep learning is a new name for neural networks, which have been around for over 70 years.', 'Neural networks were first proposed in 1944 and experienced periods of popularity and decline.', 'Deep learning has become popular again in recent years due to increased processing power.', 'Neural nets are a form of machine learning, where a computer learns from training examples.', 'Neural nets consist of interconnected processing nodes and are organized into layers.', 'During training, the weights and thresholds of neural nets are adjusted to yield consistent outputs.', 'Neural nets have been used in neuroscientific research to understand how the brain processes information.', 'The Perceptron, a trainable neural network, was demonstrated in 1957.', 'Neural nets faced limitations in the past, but algorithms developed in the 1980s removed many of these limitations.', 'The recent resurgence in neural networks is attributed to the development of graphics processing units (GPUs).', 'Deep learning, characterized by the depth of network layers, is responsible for the best-performing AI systems.', 'There is ongoing research to understand the analytic strategies adopted by neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414'}}, {'concise_summary': 'Neural networks are a subset of machine learning and are at the heart of deep learning algorithms. They mimic the way biological neurons signal to one another. Neural networks rely on training data to improve their accuracy over time and are powerful tools in computer science and artificial intelligence. They can classify and cluster data quickly, such as in speech recognition or image recognition tasks. Google's search algorithm is a well-known neural network.', 'writing_style': 'The text provides a clear explanation of neural networks and their structure. It uses examples and equations to illustrate how neural networks work.', 'key_points': ['Neural networks are inspired by the human brain and mimic the way neurons signal to one another.', 'They consist of node layers, including an input layer, hidden layers, and an output layer.', 'Each node has an associated weight and threshold, and if the output exceeds the threshold, the node is activated.', 'Neural networks rely on training data to improve their accuracy over time.', 'They are powerful tools in computer science and artificial intelligence, allowing for quick classification and clustering of data.', 'Google's search algorithm is a well-known neural network.', 'Neural networks leverage sigmoid neurons, which have values between 0 and 1, and this reduces the impact of changes in variables on the output.', 'Supervised learning and cost functions, such as mean squared error, are used to train neural networks.', 'Gradient descent and backpropagation are techniques used to adjust the weights and minimize the cost function.', 'Different types of neural networks include feedforward neural networks, convolutional neural networks, and recurrent neural networks.', 'Deep learning refers to neural networks with more than three layers, while basic neural networks have two or three layers.', 'The history of neural networks dates back to the 1940s and includes key milestones such as the development of the perceptron and the concept of backpropagation.', 'In 1943, Warren S. McCulloch and Walter Pitts published a research paper that compared neurons to a binary threshold and laid the foundation for neural networks.', 'Frank Rosenblatt's development of the perceptron in 1958 introduced weights to neural networks and enabled computers to learn and distinguish patterns.', 'Paul Werbos noted the application of backpropagation in neural networks in 1974, contributing to the advancement of the field.', 'Yann LeCun's research in 1989 demonstrated the successful use of neural networks to recognize hand-written zip code digits.', 'Neural networks are used in various applications, including speech recognition and image recognition tasks.'], 'expert_opinions': [], 'metadata': {'source': 'https://www.ibm.com/topics/neural-networks'}}]\", 'topic': 'Neural networks'}\"\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a content SEO researcher. Previously you have summarized and extracted key points from SERP results. \\n        The insights gained will be used to do content research and we will compare the key points, insights and summaries across multiple articles.\\n        You are now going to interview a content expert. You will ask them questions about the following topic: Neural networks.\\n\\n        You must follow the following rules:\\n        - Return a list of questions that you would ask a content expert about the topic.\\n        - You must ask at least 5 questions.\\n        - You are looking for information gain and unique insights that are not already covered in the [{'concise_summary': 'Neural network theory helps understand how neurons in the brain function and create artificial intelligence. The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James. Artificial neural networks are used for solving AI problems and can derive conclusions from complex information. The history of neural networks includes the development of computational models and the discovery of Hebbian learning. The backpropagation algorithm and the increase in computer processing power have further advanced neural network research. Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'writing_style': 'The text provides a historical overview of neural network theory and its applications in artificial intelligence. It highlights the development of computational models, the discovery of Hebbian learning, and the advancements enabled by the backpropagation algorithm and increased computer processing power. The writing style is informative and objective.', 'key_points': ['Neural network theory helps understand how neurons in the brain function and create artificial intelligence.', 'The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James.', 'Artificial neural networks are used for solving AI problems and can derive conclusions from complex information.', 'The history of neural networks includes the development of computational models and the discovery of Hebbian learning.', 'The backpropagation algorithm and the increase in computer processing power have further advanced neural network research.', 'Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'Recent emphasis on the explainability of AI has contributed towards the development of methods for visualizing and explaining learned neural networks.', 'Researchers are uncovering generic principles that allow a learning machine to be successful.', 'Hybrid models combining neural networks and symbolic approaches are advocated by some researchers.', 'The role of neuromodulators such as dopamine, acetylcholine, and serotonin on behavior and learning is being explored.', 'Biophysical models and computational algorithms used in the brain are being studied.', 'Computational devices for neuromorphic computing and nanodevices for neural computing are being developed.', 'Recurrent neural networks and deep feedforward neural networks have achieved success in pattern recognition and machine learning competitions.', 'Variants of the backpropagation algorithm and unsupervised methods are used to train deep, highly nonlinear neural architectures.', 'Radial basis function and wavelet networks offer best approximation properties and have applications in nonlinear system identification and classification.', 'Analytical and computational techniques derived from statistical physics can be applied to analyze the weight space of deep neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://en.wikipedia.org/wiki/Neural_network'}}, {'concise_summary': 'Deep learning is a technique in artificial intelligence that has been around for over 70 years. It involves neural networks, which were first proposed in 1944. Neural networks fell out of favor in the late 1960s but experienced a resurgence in the 1980s and again in the 2000s. Deep learning has become popular in recent years due to increased processing power. Neural nets are a form of machine learning, where a computer learns to perform tasks by analyzing training examples.', 'writing_style': 'Informative', 'key_points': ['Deep learning is a new name for neural networks, which have been around for over 70 years.', 'Neural networks were first proposed in 1944 and experienced periods of popularity and decline.', 'Deep learning has become popular again in recent years due to increased processing power.', 'Neural nets are a form of machine learning, where a computer learns from training examples.', 'Neural nets consist of interconnected processing nodes and are organized into layers.', 'During training, the weights and thresholds of neural nets are adjusted to yield consistent outputs.', 'Neural nets have been used in neuroscientific research to understand how the brain processes information.', 'The Perceptron, a trainable neural network, was demonstrated in 1957.', 'Neural nets faced limitations in the past, but algorithms developed in the 1980s removed many of these limitations.', 'The recent resurgence in neural networks is attributed to the development of graphics processing units (GPUs).', 'Deep learning, characterized by the depth of network layers, is responsible for the best-performing AI systems.', 'There is ongoing research to understand the analytic strategies adopted by neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414'}}, {'concise_summary': 'Neural networks are a subset of machine learning and are at the heart of deep learning algorithms. They mimic the way biological neurons signal to one another. Neural networks rely on training data to improve their accuracy over time and are powerful tools in computer science and artificial intelligence. They can classify and cluster data quickly, such as in speech recognition or image recognition tasks. Google's search algorithm is a well-known neural network.', 'writing_style': 'The text provides a clear explanation of neural networks and their structure. It uses examples and equations to illustrate how neural networks work.', 'key_points': ['Neural networks are inspired by the human brain and mimic the way neurons signal to one another.', 'They consist of node layers, including an input layer, hidden layers, and an output layer.', 'Each node has an associated weight and threshold, and if the output exceeds the threshold, the node is activated.', 'Neural networks rely on training data to improve their accuracy over time.', 'They are powerful tools in computer science and artificial intelligence, allowing for quick classification and clustering of data.', 'Google's search algorithm is a well-known neural network.', 'Neural networks leverage sigmoid neurons, which have values between 0 and 1, and this reduces the impact of changes in variables on the output.', 'Supervised learning and cost functions, such as mean squared error, are used to train neural networks.', 'Gradient descent and backpropagation are techniques used to adjust the weights and minimize the cost function.', 'Different types of neural networks include feedforward neural networks, convolutional neural networks, and recurrent neural networks.', 'Deep learning refers to neural networks with more than three layers, while basic neural networks have two or three layers.', 'The history of neural networks dates back to the 1940s and includes key milestones such as the development of the perceptron and the concept of backpropagation.', 'In 1943, Warren S. McCulloch and Walter Pitts published a research paper that compared neurons to a binary threshold and laid the foundation for neural networks.', 'Frank Rosenblatt's development of the perceptron in 1958 introduced weights to neural networks and enabled computers to learn and distinguish patterns.', 'Paul Werbos noted the application of backpropagation in neural networks in 1974, contributing to the advancement of the field.', 'Yann LeCun's research in 1989 demonstrated the successful use of neural networks to recognize hand-written zip code digits.', 'Neural networks are used in various applications, including speech recognition and image recognition tasks.'], 'expert_opinions': [], 'metadata': {'source': 'https://www.ibm.com/topics/neural-networks'}}] information.\\n        - You must ask questions that are open-ended and not yes/no questions.\\n        The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"description\\\": \\\"Output for Interview questions\\\", \\\"properties\\\": {\\\"questions\\\": {\\\"title\\\": \\\"Questions\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"$ref\\\": \\\"#/definitions/Question\\\"}}}, \\\"required\\\": [\\\"questions\\\"], \\\"definitions\\\": {\\\"Question\\\": {\\\"title\\\": \\\"Question\\\", \\\"description\\\": \\\"Single Output - A question with no answer\\\", \\\"type\\\": \\\"object\\\", \\\"properties\\\": {\\\"question\\\": {\\\"title\\\": \\\"Question\\\", \\\"description\\\": \\\"An interview question to ask.\\\", \\\"type\\\": \\\"string\\\"}, \\\"answer\\\": {\\\"title\\\": \\\"Answer\\\", \\\"type\\\": \\\"null\\\"}}}}}\\n```\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [3.48s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"questions\\\": [\\n    {\\\"question\\\": \\\"What are the key milestones in the history of neural networks?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"How do neural networks mimic the way biological neurons signal to one another?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"What are the different types of neural networks and their applications?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"What are the techniques used to train neural networks?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"How has deep learning become popular again in recent years?\\\", \\\"answer\\\": null}\\n]}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"questions\\\": [\\n    {\\\"question\\\": \\\"What are the key milestones in the history of neural networks?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"How do neural networks mimic the way biological neurons signal to one another?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"What are the different types of neural networks and their applications?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"What are the techniques used to train neural networks?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"How has deep learning become popular again in recent years?\\\", \\\"answer\\\": null}\\n]}\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 1852,\n",
      "      \"completion_tokens\": 114,\n",
      "      \"total_tokens\": 1966\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 3:tool:generate_interview_questions] [3.48s] Exiting Tool run with output:\n",
      "\u001b[0m\"{\"questions\": [\n",
      "    {\"question\": \"What are the key milestones in the history of neural networks?\", \"answer\": null},\n",
      "    {\"question\": \"How do neural networks mimic the way biological neurons signal to one another?\", \"answer\": null},\n",
      "    {\"question\": \"What are the different types of neural networks and their applications?\", \"answer\": null},\n",
      "    {\"question\": \"What are the techniques used to train neural networks?\", \"answer\": null},\n",
      "    {\"question\": \"How has deep learning become popular again in recent years?\", \"answer\": null}\n",
      "]}\"\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are very powerful assistant and are responsible for investigating the following topic: Neural networks. \\n                               You are bad at extracting key points from articles and need help.\\n                               Also you must let the human answer questions as this is their interview.\\n                               ---\\n                               \\nHuman: My name is James, what is your name?\\nAI: Hello James, I'm OpenAI's language model. I don't have a personal name as I'm an artificial intelligence. How can I assist you today?\\nHuman: What is my name?\\nAI: Your name is James.\\nHuman: Here is some useful information for later on:\\n                   document_summaries: [{'concise_summary': 'Neural network theory helps understand how neurons in the brain function and create artificial intelligence. The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James. Artificial neural networks are used for solving AI problems and can derive conclusions from complex information. The history of neural networks includes the development of computational models and the discovery of Hebbian learning. The backpropagation algorithm and the increase in computer processing power have further advanced neural network research. Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'writing_style': 'The text provides a historical overview of neural network theory and its applications in artificial intelligence. It highlights the development of computational models, the discovery of Hebbian learning, and the advancements enabled by the backpropagation algorithm and increased computer processing power. The writing style is informative and objective.', 'key_points': ['Neural network theory helps understand how neurons in the brain function and create artificial intelligence.', 'The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James.', 'Artificial neural networks are used for solving AI problems and can derive conclusions from complex information.', 'The history of neural networks includes the development of computational models and the discovery of Hebbian learning.', 'The backpropagation algorithm and the increase in computer processing power have further advanced neural network research.', 'Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'Recent emphasis on the explainability of AI has contributed towards the development of methods for visualizing and explaining learned neural networks.', 'Researchers are uncovering generic principles that allow a learning machine to be successful.', 'Hybrid models combining neural networks and symbolic approaches are advocated by some researchers.', 'The role of neuromodulators such as dopamine, acetylcholine, and serotonin on behavior and learning is being explored.', 'Biophysical models and computational algorithms used in the brain are being studied.', 'Computational devices for neuromorphic computing and nanodevices for neural computing are being developed.', 'Recurrent neural networks and deep feedforward neural networks have achieved success in pattern recognition and machine learning competitions.', 'Variants of the backpropagation algorithm and unsupervised methods are used to train deep, highly nonlinear neural architectures.', 'Radial basis function and wavelet networks offer best approximation properties and have applications in nonlinear system identification and classification.', 'Analytical and computational techniques derived from statistical physics can be applied to analyze the weight space of deep neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://en.wikipedia.org/wiki/Neural_network'}}, {'concise_summary': 'Deep learning is a technique in artificial intelligence that has been around for over 70 years. It involves neural networks, which were first proposed in 1944. Neural networks fell out of favor in the late 1960s but experienced a resurgence in the 1980s and again in the 2000s. Deep learning has become popular in recent years due to increased processing power. Neural nets are a form of machine learning, where a computer learns to perform tasks by analyzing training examples.', 'writing_style': 'Informative', 'key_points': ['Deep learning is a new name for neural networks, which have been around for over 70 years.', 'Neural networks were first proposed in 1944 and experienced periods of popularity and decline.', 'Deep learning has become popular again in recent years due to increased processing power.', 'Neural nets are a form of machine learning, where a computer learns from training examples.', 'Neural nets consist of interconnected processing nodes and are organized into layers.', 'During training, the weights and thresholds of neural nets are adjusted to yield consistent outputs.', 'Neural nets have been used in neuroscientific research to understand how the brain processes information.', 'The Perceptron, a trainable neural network, was demonstrated in 1957.', 'Neural nets faced limitations in the past, but algorithms developed in the 1980s removed many of these limitations.', 'The recent resurgence in neural networks is attributed to the development of graphics processing units (GPUs).', 'Deep learning, characterized by the depth of network layers, is responsible for the best-performing AI systems.', 'There is ongoing research to understand the analytic strategies adopted by neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414'}}, {'concise_summary': \\\"Neural networks are a subset of machine learning and are at the heart of deep learning algorithms. They mimic the way biological neurons signal to one another. Neural networks rely on training data to improve their accuracy over time and are powerful tools in computer science and artificial intelligence. They can classify and cluster data quickly, such as in speech recognition or image recognition tasks. Google's search algorithm is a well-known neural network.\\\", 'writing_style': 'The text provides a clear explanation of neural networks and their structure. It uses examples and equations to illustrate how neural networks work.', 'key_points': ['Neural networks are inspired by the human brain and mimic the way neurons signal to one another.', 'They consist of node layers, including an input layer, hidden layers, and an output layer.', 'Each node has an associated weight and threshold, and if the output exceeds the threshold, the node is activated.', 'Neural networks rely on training data to improve their accuracy over time.', 'They are powerful tools in computer science and artificial intelligence, allowing for quick classification and clustering of data.', \\\"Google's search algorithm is a well-known neural network.\\\", 'Neural networks leverage sigmoid neurons, which have values between 0 and 1, and this reduces the impact of changes in variables on the output.', 'Supervised learning and cost functions, such as mean squared error, are used to train neural networks.', 'Gradient descent and backpropagation are techniques used to adjust the weights and minimize the cost function.', 'Different types of neural networks include feedforward neural networks, convolutional neural networks, and recurrent neural networks.', 'Deep learning refers to neural networks with more than three layers, while basic neural networks have two or three layers.', 'The history of neural networks dates back to the 1940s and includes key milestones such as the development of the perceptron and the concept of backpropagation.', 'In 1943, Warren S. McCulloch and Walter Pitts published a research paper that compared neurons to a binary threshold and laid the foundation for neural networks.', \\\"Frank Rosenblatt's development of the perceptron in 1958 introduced weights to neural networks and enabled computers to learn and distinguish patterns.\\\", 'Paul Werbos noted the application of backpropagation in neural networks in 1974, contributing to the advancement of the field.', \\\"Yann LeCun's research in 1989 demonstrated the successful use of neural networks to recognize hand-written zip code digits.\\\", 'Neural networks are used in various applications, including speech recognition and image recognition tasks.'], 'expert_opinions': [], 'metadata': {'source': 'https://www.ibm.com/topics/neural-networks'}}]\\n                   topic: Neural networks\\n                   \\nAI: {'name': 'generate_interview_questions', 'arguments': '{\\\\n\\\"document_summaries\\\": \\\"[{\\\\'concise_summary\\\\': \\\\'Neural network theory helps understand how neurons in the brain function and create artificial intelligence. The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James. Artificial neural networks are used for solving AI problems and can derive conclusions from complex information. The history of neural networks includes the development of computational models and the discovery of Hebbian learning. The backpropagation algorithm and the increase in computer processing power have further advanced neural network research. Neural networks in artificial intelligence are simplified models of neural processing in the brain.\\\\', \\\\'writing_style\\\\': \\\\'The text provides a historical overview of neural network theory and its applications in artificial intelligence. It highlights the development of computational models, the discovery of Hebbian learning, and the advancements enabled by the backpropagation algorithm and increased computer processing power. The writing style is informative and objective.\\\\', \\\\'key_points\\\\': [\\\\'Neural network theory helps understand how neurons in the brain function and create artificial intelligence.\\\\', \\\\'The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James.\\\\', \\\\'Artificial neural networks are used for solving AI problems and can derive conclusions from complex information.\\\\', \\\\'The history of neural networks includes the development of computational models and the discovery of Hebbian learning.\\\\', \\\\'The backpropagation algorithm and the increase in computer processing power have further advanced neural network research.\\\\', \\\\'Neural networks in artificial intelligence are simplified models of neural processing in the brain.\\\\', \\\\'Recent emphasis on the explainability of AI has contributed towards the development of methods for visualizing and explaining learned neural networks.\\\\', \\\\'Researchers are uncovering generic principles that allow a learning machine to be successful.\\\\', \\\\'Hybrid models combining neural networks and symbolic approaches are advocated by some researchers.\\\\', \\\\'The role of neuromodulators such as dopamine, acetylcholine, and serotonin on behavior and learning is being explored.\\\\', \\\\'Biophysical models and computational algorithms used in the brain are being studied.\\\\', \\\\'Computational devices for neuromorphic computing and nanodevices for neural computing are being developed.\\\\', \\\\'Recurrent neural networks and deep feedforward neural networks have achieved success in pattern recognition and machine learning competitions.\\\\', \\\\'Variants of the backpropagation algorithm and unsupervised methods are used to train deep, highly nonlinear neural architectures.\\\\', \\\\'Radial basis function and wavelet networks offer best approximation properties and have applications in nonlinear system identification and classification.\\\\', \\\\'Analytical and computational techniques derived from statistical physics can be applied to analyze the weight space of deep neural networks.\\\\'], \\\\'expert_opinions\\\\': [], \\\\'metadata\\\\': {\\\\'source\\\\': \\\\'https://en.wikipedia.org/wiki/Neural_network\\\\'}}, {\\\\'concise_summary\\\\': \\\\'Deep learning is a technique in artificial intelligence that has been around for over 70 years. It involves neural networks, which were first proposed in 1944. Neural networks fell out of favor in the late 1960s but experienced a resurgence in the 1980s and again in the 2000s. Deep learning has become popular in recent years due to increased processing power. Neural nets are a form of machine learning, where a computer learns to perform tasks by analyzing training examples.\\\\', \\\\'writing_style\\\\': \\\\'Informative\\\\', \\\\'key_points\\\\': [\\\\'Deep learning is a new name for neural networks, which have been around for over 70 years.\\\\', \\\\'Neural networks were first proposed in 1944 and experienced periods of popularity and decline.\\\\', \\\\'Deep learning has become popular again in recent years due to increased processing power.\\\\', \\\\'Neural nets are a form of machine learning, where a computer learns from training examples.\\\\', \\\\'Neural nets consist of interconnected processing nodes and are organized into layers.\\\\', \\\\'During training, the weights and thresholds of neural nets are adjusted to yield consistent outputs.\\\\', \\\\'Neural nets have been used in neuroscientific research to understand how the brain processes information.\\\\', \\\\'The Perceptron, a trainable neural network, was demonstrated in 1957.\\\\', \\\\'Neural nets faced limitations in the past, but algorithms developed in the 1980s removed many of these limitations.\\\\', \\\\'The recent resurgence in neural networks is attributed to the development of graphics processing units (GPUs).\\\\', \\\\'Deep learning, characterized by the depth of network layers, is responsible for the best-performing AI systems.\\\\', \\\\'There is ongoing research to understand the analytic strategies adopted by neural networks.\\\\'], \\\\'expert_opinions\\\\': [], \\\\'metadata\\\\': {\\\\'source\\\\': \\\\'https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414\\\\'}}, {\\\\'concise_summary\\\\': \\\\'Neural networks are a subset of machine learning and are at the heart of deep learning algorithms. They mimic the way biological neurons signal to one another. Neural networks rely on training data to improve their accuracy over time and are powerful tools in computer science and artificial intelligence. They can classify and cluster data quickly, such as in speech recognition or image recognition tasks. Google\\\\'s search algorithm is a well-known neural network.\\\\', \\\\'writing_style\\\\': \\\\'The text provides a clear explanation of neural networks and their structure. It uses examples and equations to illustrate how neural networks work.\\\\', \\\\'key_points\\\\': [\\\\'Neural networks are inspired by the human brain and mimic the way neurons signal to one another.\\\\', \\\\'They consist of node layers, including an input layer, hidden layers, and an output layer.\\\\', \\\\'Each node has an associated weight and threshold, and if the output exceeds the threshold, the node is activated.\\\\', \\\\'Neural networks rely on training data to improve their accuracy over time.\\\\', \\\\'They are powerful tools in computer science and artificial intelligence, allowing for quick classification and clustering of data.\\\\', \\\\'Google\\\\'s search algorithm is a well-known neural network.\\\\', \\\\'Neural networks leverage sigmoid neurons, which have values between 0 and 1, and this reduces the impact of changes in variables on the output.\\\\', \\\\'Supervised learning and cost functions, such as mean squared error, are used to train neural networks.\\\\', \\\\'Gradient descent and backpropagation are techniques used to adjust the weights and minimize the cost function.\\\\', \\\\'Different types of neural networks include feedforward neural networks, convolutional neural networks, and recurrent neural networks.\\\\', \\\\'Deep learning refers to neural networks with more than three layers, while basic neural networks have two or three layers.\\\\', \\\\'The history of neural networks dates back to the 1940s and includes key milestones such as the development of the perceptron and the concept of backpropagation.\\\\', \\\\'In 1943, Warren S. McCulloch and Walter Pitts published a research paper that compared neurons to a binary threshold and laid the foundation for neural networks.\\\\', \\\\'Frank Rosenblatt\\\\'s development of the perceptron in 1958 introduced weights to neural networks and enabled computers to learn and distinguish patterns.\\\\', \\\\'Paul Werbos noted the application of backpropagation in neural networks in 1974, contributing to the advancement of the field.\\\\', \\\\'Yann LeCun\\\\'s research in 1989 demonstrated the successful use of neural networks to recognize hand-written zip code digits.\\\\', \\\\'Neural networks are used in various applications, including speech recognition and image recognition tasks.\\\\'], \\\\'expert_opinions\\\\': [], \\\\'metadata\\\\': {\\\\'source\\\\': \\\\'https://www.ibm.com/topics/neural-networks\\\\'}}]\\\",\\\\n\\\"topic\\\": \\\"Neural networks\\\"\\\\n}'}\\nFunction: {\\\"questions\\\": [\\n    {\\\"question\\\": \\\"What are the key milestones in the history of neural networks?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"How do neural networks mimic the way biological neurons signal to one another?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"What are the different types of neural networks and their applications?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"What are the techniques used to train neural networks?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"How has deep learning become popular again in recent years?\\\", \\\"answer\\\": null}\\n]}\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:llm:ChatOpenAI] [7.58s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"function_call\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"human_in_the_loop_answer_question\",\n",
      "                \"arguments\": \"{\\n\\\"questions\\\": [\\\"What are the key milestones in the history of neural networks?\\\", \\\"How do neural networks mimic the way biological neurons signal to one another?\\\", \\\"What are the different types of neural networks and their applications?\\\", \\\"What are the techniques used to train neural networks?\\\", \\\"How has deep learning become popular again in recent years?\\\"]\\n}\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 3385,\n",
      "      \"completion_tokens\": 81,\n",
      "      \"total_tokens\": 3466\n",
      "    },\n",
      "    \"model_name\": \"gpt-4\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:tool:human_in_the_loop_answer_question] Entering Tool run with input:\n",
      "\u001b[0m\"{'questions': ['What are the key milestones in the history of neural networks?', 'How do neural networks mimic the way biological neurons signal to one another?', 'What are the different types of neural networks and their applications?', 'What are the techniques used to train neural networks?', 'How has deep learning become popular again in recent years?']}\"\n",
      "\n",
      "\n",
      "What are the key milestones in the history of neural networks?\n",
      "\n",
      "\n",
      "How do neural networks mimic the way biological neurons signal to one another?\n",
      "\n",
      "\n",
      "What are the different types of neural networks and their applications?\n",
      "\n",
      "\n",
      "What are the techniques used to train neural networks?\n",
      "\n",
      "\n",
      "How has deep learning become popular again in recent years?\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:tool:human_in_the_loop_answer_question] [2355.10s] Exiting Tool run with output:\n",
      "\u001b[0m\"[{'question': 'What are the key milestones in the history of neural networks?', 'answer': ''}, {'question': 'How do neural networks mimic the way biological neurons signal to one another?', 'answer': ''}, {'question': 'What are the different types of neural networks and their applications?', 'answer': ''}, {'question': 'What are the techniques used to train neural networks?', 'answer': ''}, {'question': 'How has deep learning become popular again in recent years?', 'answer': ''}]\"\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 6:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are very powerful assistant and are responsible for investigating the following topic: Neural networks. \\n                               You are bad at extracting key points from articles and need help.\\n                               Also you must let the human answer questions as this is their interview.\\n                               ---\\n                               \\nHuman: My name is James, what is your name?\\nAI: Hello James, I'm OpenAI's language model. I don't have a personal name as I'm an artificial intelligence. How can I assist you today?\\nHuman: What is my name?\\nAI: Your name is James.\\nHuman: Here is some useful information for later on:\\n                   document_summaries: [{'concise_summary': 'Neural network theory helps understand how neurons in the brain function and create artificial intelligence. The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James. Artificial neural networks are used for solving AI problems and can derive conclusions from complex information. The history of neural networks includes the development of computational models and the discovery of Hebbian learning. The backpropagation algorithm and the increase in computer processing power have further advanced neural network research. Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'writing_style': 'The text provides a historical overview of neural network theory and its applications in artificial intelligence. It highlights the development of computational models, the discovery of Hebbian learning, and the advancements enabled by the backpropagation algorithm and increased computer processing power. The writing style is informative and objective.', 'key_points': ['Neural network theory helps understand how neurons in the brain function and create artificial intelligence.', 'The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James.', 'Artificial neural networks are used for solving AI problems and can derive conclusions from complex information.', 'The history of neural networks includes the development of computational models and the discovery of Hebbian learning.', 'The backpropagation algorithm and the increase in computer processing power have further advanced neural network research.', 'Neural networks in artificial intelligence are simplified models of neural processing in the brain.', 'Recent emphasis on the explainability of AI has contributed towards the development of methods for visualizing and explaining learned neural networks.', 'Researchers are uncovering generic principles that allow a learning machine to be successful.', 'Hybrid models combining neural networks and symbolic approaches are advocated by some researchers.', 'The role of neuromodulators such as dopamine, acetylcholine, and serotonin on behavior and learning is being explored.', 'Biophysical models and computational algorithms used in the brain are being studied.', 'Computational devices for neuromorphic computing and nanodevices for neural computing are being developed.', 'Recurrent neural networks and deep feedforward neural networks have achieved success in pattern recognition and machine learning competitions.', 'Variants of the backpropagation algorithm and unsupervised methods are used to train deep, highly nonlinear neural architectures.', 'Radial basis function and wavelet networks offer best approximation properties and have applications in nonlinear system identification and classification.', 'Analytical and computational techniques derived from statistical physics can be applied to analyze the weight space of deep neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://en.wikipedia.org/wiki/Neural_network'}}, {'concise_summary': 'Deep learning is a technique in artificial intelligence that has been around for over 70 years. It involves neural networks, which were first proposed in 1944. Neural networks fell out of favor in the late 1960s but experienced a resurgence in the 1980s and again in the 2000s. Deep learning has become popular in recent years due to increased processing power. Neural nets are a form of machine learning, where a computer learns to perform tasks by analyzing training examples.', 'writing_style': 'Informative', 'key_points': ['Deep learning is a new name for neural networks, which have been around for over 70 years.', 'Neural networks were first proposed in 1944 and experienced periods of popularity and decline.', 'Deep learning has become popular again in recent years due to increased processing power.', 'Neural nets are a form of machine learning, where a computer learns from training examples.', 'Neural nets consist of interconnected processing nodes and are organized into layers.', 'During training, the weights and thresholds of neural nets are adjusted to yield consistent outputs.', 'Neural nets have been used in neuroscientific research to understand how the brain processes information.', 'The Perceptron, a trainable neural network, was demonstrated in 1957.', 'Neural nets faced limitations in the past, but algorithms developed in the 1980s removed many of these limitations.', 'The recent resurgence in neural networks is attributed to the development of graphics processing units (GPUs).', 'Deep learning, characterized by the depth of network layers, is responsible for the best-performing AI systems.', 'There is ongoing research to understand the analytic strategies adopted by neural networks.'], 'expert_opinions': [], 'metadata': {'source': 'https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414'}}, {'concise_summary': \\\"Neural networks are a subset of machine learning and are at the heart of deep learning algorithms. They mimic the way biological neurons signal to one another. Neural networks rely on training data to improve their accuracy over time and are powerful tools in computer science and artificial intelligence. They can classify and cluster data quickly, such as in speech recognition or image recognition tasks. Google's search algorithm is a well-known neural network.\\\", 'writing_style': 'The text provides a clear explanation of neural networks and their structure. It uses examples and equations to illustrate how neural networks work.', 'key_points': ['Neural networks are inspired by the human brain and mimic the way neurons signal to one another.', 'They consist of node layers, including an input layer, hidden layers, and an output layer.', 'Each node has an associated weight and threshold, and if the output exceeds the threshold, the node is activated.', 'Neural networks rely on training data to improve their accuracy over time.', 'They are powerful tools in computer science and artificial intelligence, allowing for quick classification and clustering of data.', \\\"Google's search algorithm is a well-known neural network.\\\", 'Neural networks leverage sigmoid neurons, which have values between 0 and 1, and this reduces the impact of changes in variables on the output.', 'Supervised learning and cost functions, such as mean squared error, are used to train neural networks.', 'Gradient descent and backpropagation are techniques used to adjust the weights and minimize the cost function.', 'Different types of neural networks include feedforward neural networks, convolutional neural networks, and recurrent neural networks.', 'Deep learning refers to neural networks with more than three layers, while basic neural networks have two or three layers.', 'The history of neural networks dates back to the 1940s and includes key milestones such as the development of the perceptron and the concept of backpropagation.', 'In 1943, Warren S. McCulloch and Walter Pitts published a research paper that compared neurons to a binary threshold and laid the foundation for neural networks.', \\\"Frank Rosenblatt's development of the perceptron in 1958 introduced weights to neural networks and enabled computers to learn and distinguish patterns.\\\", 'Paul Werbos noted the application of backpropagation in neural networks in 1974, contributing to the advancement of the field.', \\\"Yann LeCun's research in 1989 demonstrated the successful use of neural networks to recognize hand-written zip code digits.\\\", 'Neural networks are used in various applications, including speech recognition and image recognition tasks.'], 'expert_opinions': [], 'metadata': {'source': 'https://www.ibm.com/topics/neural-networks'}}]\\n                   topic: Neural networks\\n                   \\nAI: {'name': 'generate_interview_questions', 'arguments': '{\\\\n\\\"document_summaries\\\": \\\"[{\\\\'concise_summary\\\\': \\\\'Neural network theory helps understand how neurons in the brain function and create artificial intelligence. The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James. Artificial neural networks are used for solving AI problems and can derive conclusions from complex information. The history of neural networks includes the development of computational models and the discovery of Hebbian learning. The backpropagation algorithm and the increase in computer processing power have further advanced neural network research. Neural networks in artificial intelligence are simplified models of neural processing in the brain.\\\\', \\\\'writing_style\\\\': \\\\'The text provides a historical overview of neural network theory and its applications in artificial intelligence. It highlights the development of computational models, the discovery of Hebbian learning, and the advancements enabled by the backpropagation algorithm and increased computer processing power. The writing style is informative and objective.\\\\', \\\\'key_points\\\\': [\\\\'Neural network theory helps understand how neurons in the brain function and create artificial intelligence.\\\\', \\\\'The preliminary theoretical base for contemporary neural networks was proposed by Alexander Bain and William James.\\\\', \\\\'Artificial neural networks are used for solving AI problems and can derive conclusions from complex information.\\\\', \\\\'The history of neural networks includes the development of computational models and the discovery of Hebbian learning.\\\\', \\\\'The backpropagation algorithm and the increase in computer processing power have further advanced neural network research.\\\\', \\\\'Neural networks in artificial intelligence are simplified models of neural processing in the brain.\\\\', \\\\'Recent emphasis on the explainability of AI has contributed towards the development of methods for visualizing and explaining learned neural networks.\\\\', \\\\'Researchers are uncovering generic principles that allow a learning machine to be successful.\\\\', \\\\'Hybrid models combining neural networks and symbolic approaches are advocated by some researchers.\\\\', \\\\'The role of neuromodulators such as dopamine, acetylcholine, and serotonin on behavior and learning is being explored.\\\\', \\\\'Biophysical models and computational algorithms used in the brain are being studied.\\\\', \\\\'Computational devices for neuromorphic computing and nanodevices for neural computing are being developed.\\\\', \\\\'Recurrent neural networks and deep feedforward neural networks have achieved success in pattern recognition and machine learning competitions.\\\\', \\\\'Variants of the backpropagation algorithm and unsupervised methods are used to train deep, highly nonlinear neural architectures.\\\\', \\\\'Radial basis function and wavelet networks offer best approximation properties and have applications in nonlinear system identification and classification.\\\\', \\\\'Analytical and computational techniques derived from statistical physics can be applied to analyze the weight space of deep neural networks.\\\\'], \\\\'expert_opinions\\\\': [], \\\\'metadata\\\\': {\\\\'source\\\\': \\\\'https://en.wikipedia.org/wiki/Neural_network\\\\'}}, {\\\\'concise_summary\\\\': \\\\'Deep learning is a technique in artificial intelligence that has been around for over 70 years. It involves neural networks, which were first proposed in 1944. Neural networks fell out of favor in the late 1960s but experienced a resurgence in the 1980s and again in the 2000s. Deep learning has become popular in recent years due to increased processing power. Neural nets are a form of machine learning, where a computer learns to perform tasks by analyzing training examples.\\\\', \\\\'writing_style\\\\': \\\\'Informative\\\\', \\\\'key_points\\\\': [\\\\'Deep learning is a new name for neural networks, which have been around for over 70 years.\\\\', \\\\'Neural networks were first proposed in 1944 and experienced periods of popularity and decline.\\\\', \\\\'Deep learning has become popular again in recent years due to increased processing power.\\\\', \\\\'Neural nets are a form of machine learning, where a computer learns from training examples.\\\\', \\\\'Neural nets consist of interconnected processing nodes and are organized into layers.\\\\', \\\\'During training, the weights and thresholds of neural nets are adjusted to yield consistent outputs.\\\\', \\\\'Neural nets have been used in neuroscientific research to understand how the brain processes information.\\\\', \\\\'The Perceptron, a trainable neural network, was demonstrated in 1957.\\\\', \\\\'Neural nets faced limitations in the past, but algorithms developed in the 1980s removed many of these limitations.\\\\', \\\\'The recent resurgence in neural networks is attributed to the development of graphics processing units (GPUs).\\\\', \\\\'Deep learning, characterized by the depth of network layers, is responsible for the best-performing AI systems.\\\\', \\\\'There is ongoing research to understand the analytic strategies adopted by neural networks.\\\\'], \\\\'expert_opinions\\\\': [], \\\\'metadata\\\\': {\\\\'source\\\\': \\\\'https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414\\\\'}}, {\\\\'concise_summary\\\\': \\\\'Neural networks are a subset of machine learning and are at the heart of deep learning algorithms. They mimic the way biological neurons signal to one another. Neural networks rely on training data to improve their accuracy over time and are powerful tools in computer science and artificial intelligence. They can classify and cluster data quickly, such as in speech recognition or image recognition tasks. Google\\\\'s search algorithm is a well-known neural network.\\\\', \\\\'writing_style\\\\': \\\\'The text provides a clear explanation of neural networks and their structure. It uses examples and equations to illustrate how neural networks work.\\\\', \\\\'key_points\\\\': [\\\\'Neural networks are inspired by the human brain and mimic the way neurons signal to one another.\\\\', \\\\'They consist of node layers, including an input layer, hidden layers, and an output layer.\\\\', \\\\'Each node has an associated weight and threshold, and if the output exceeds the threshold, the node is activated.\\\\', \\\\'Neural networks rely on training data to improve their accuracy over time.\\\\', \\\\'They are powerful tools in computer science and artificial intelligence, allowing for quick classification and clustering of data.\\\\', \\\\'Google\\\\'s search algorithm is a well-known neural network.\\\\', \\\\'Neural networks leverage sigmoid neurons, which have values between 0 and 1, and this reduces the impact of changes in variables on the output.\\\\', \\\\'Supervised learning and cost functions, such as mean squared error, are used to train neural networks.\\\\', \\\\'Gradient descent and backpropagation are techniques used to adjust the weights and minimize the cost function.\\\\', \\\\'Different types of neural networks include feedforward neural networks, convolutional neural networks, and recurrent neural networks.\\\\', \\\\'Deep learning refers to neural networks with more than three layers, while basic neural networks have two or three layers.\\\\', \\\\'The history of neural networks dates back to the 1940s and includes key milestones such as the development of the perceptron and the concept of backpropagation.\\\\', \\\\'In 1943, Warren S. McCulloch and Walter Pitts published a research paper that compared neurons to a binary threshold and laid the foundation for neural networks.\\\\', \\\\'Frank Rosenblatt\\\\'s development of the perceptron in 1958 introduced weights to neural networks and enabled computers to learn and distinguish patterns.\\\\', \\\\'Paul Werbos noted the application of backpropagation in neural networks in 1974, contributing to the advancement of the field.\\\\', \\\\'Yann LeCun\\\\'s research in 1989 demonstrated the successful use of neural networks to recognize hand-written zip code digits.\\\\', \\\\'Neural networks are used in various applications, including speech recognition and image recognition tasks.\\\\'], \\\\'expert_opinions\\\\': [], \\\\'metadata\\\\': {\\\\'source\\\\': \\\\'https://www.ibm.com/topics/neural-networks\\\\'}}]\\\",\\\\n\\\"topic\\\": \\\"Neural networks\\\"\\\\n}'}\\nFunction: {\\\"questions\\\": [\\n    {\\\"question\\\": \\\"What are the key milestones in the history of neural networks?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"How do neural networks mimic the way biological neurons signal to one another?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"What are the different types of neural networks and their applications?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"What are the techniques used to train neural networks?\\\", \\\"answer\\\": null},\\n    {\\\"question\\\": \\\"How has deep learning become popular again in recent years?\\\", \\\"answer\\\": null}\\n]}\\nAI: {'name': 'human_in_the_loop_answer_question', 'arguments': '{\\\\n\\\"questions\\\": [\\\"What are the key milestones in the history of neural networks?\\\", \\\"How do neural networks mimic the way biological neurons signal to one another?\\\", \\\"What are the different types of neural networks and their applications?\\\", \\\"What are the techniques used to train neural networks?\\\", \\\"How has deep learning become popular again in recent years?\\\"]\\\\n}'}\\nFunction: [{\\\"question\\\": \\\"What are the key milestones in the history of neural networks?\\\", \\\"answer\\\": \\\"\\\"}, {\\\"question\\\": \\\"How do neural networks mimic the way biological neurons signal to one another?\\\", \\\"answer\\\": \\\"\\\"}, {\\\"question\\\": \\\"What are the different types of neural networks and their applications?\\\", \\\"answer\\\": \\\"\\\"}, {\\\"question\\\": \\\"What are the techniques used to train neural networks?\\\", \\\"answer\\\": \\\"\\\"}, {\\\"question\\\": \\\"How has deep learning become popular again in recent years?\\\", \\\"answer\\\": \\\"\\\"}]\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 6:llm:ChatOpenAI] [4.44s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Thank you for your responses. I will now save this information for future reference.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"function_call\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Thank you for your responses. I will now save this information for future reference.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"save_json_file\",\n",
      "                \"arguments\": \"{\\n\\\"file_name\\\": \\\"neural_networks_interview.json\\\"\\n}\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 3583,\n",
      "      \"completion_tokens\": 39,\n",
      "      \"total_tokens\": 3622\n",
      "    },\n",
      "    \"model_name\": \"gpt-4\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [2623.48s] Chain run errored with error:\n",
      "\u001b[0m\"ValidationError(model='SaveJsonFileArgsSchema', errors=[{'loc': ('content',), 'msg': 'field required', 'type': 'value_error.missing'}])\"\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SaveJsonFileArgsSchema\ncontent\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_y/20jl658s4jl0zvy5c0x0c5140000gn/T/ipykernel_21453/3211672415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m agent_executor.run(f\"\"\"Here is some useful information for later on:\n\u001b[0m\u001b[1;32m      2\u001b[0m                    \u001b[0mdocument_summaries\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    \u001b[0mtopic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mTOPIC\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \"\"\")\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             ]\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             outputs = (\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1037\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    889\u001b[0m                     \u001b[0mtool_run_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"llm_prefix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0;31m# We then call the tool on the tool input to get an observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 observation = tool.run(\n\u001b[0m\u001b[1;32m    892\u001b[0m                     \u001b[0magent_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     ) -> Any:\n\u001b[1;32m    297\u001b[0m         \u001b[0;34m\"\"\"Run the tool.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mparsed_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mverbose_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36m_parse_input\u001b[0;34m(self, tool_input)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtool_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtool_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/main.cpython-39-darwin.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.parse_obj\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/main.cpython-39-darwin.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for SaveJsonFileArgsSchema\ncontent\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "agent_executor.run(f\"\"\"Here is some useful information for later on:\n",
    "                   document_summaries: {[s.dict() for s in summaries]}\n",
    "                   topic: {TOPIC}\n",
    "                   \"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## General Article Outline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Article Text Generation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Re-write the Article:\n",
    "\n",
    "- Read this - https://blog.langchain.dev/using-langsmith-to-support-fine-tuning-of-open-source-llms/\n",
    "- Use this? https://github.com/langchain-ai/twitter-finetune/tree/main\n",
    "- Use chat loaders -> https://python.langchain.com/docs/integrations/chat_loaders/?ref=blog.langchain.dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Title Tag Optimization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Interface (use Mike's to do this):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
