{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.document_loaders import AsyncHtmlLoader, AsyncChromiumLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from serpapi import GoogleSearch\n",
    "import os\n",
    "from typing import Dict, List, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nest_asyncio --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Research:\n",
    "\n",
    "Use a browsing agent to search for the top 3 posts on a topic and summarize them. Progressive summarization and agent tool use.\n",
    "\n",
    "- https://python.langchain.com/docs/use_cases/web_scraping/#loader\n",
    "- https://python.langchain.com/docs/modules/data_connection/retrievers/web_research - Not viable for production, because it is only question based answering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-search-results --quiet\n",
    "%pip install html2text --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest-playwright in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (0.4.2)\n",
      "Requirement already satisfied: python-slugify<9.0.0,>=6.0.0 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest-playwright) (8.0.1)\n",
      "Requirement already satisfied: playwright>=1.18 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest-playwright) (1.37.0)\n",
      "Requirement already satisfied: pytest<8.0.0,>=6.2.4 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest-playwright) (7.1.2)\n",
      "Requirement already satisfied: pytest-base-url<3.0.0,>=1.0.0 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest-playwright) (2.0.0)\n",
      "Requirement already satisfied: pyee==9.0.4 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from playwright>=1.18->pytest-playwright) (9.0.4)\n",
      "Requirement already satisfied: greenlet==2.0.2 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from playwright>=1.18->pytest-playwright) (2.0.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pyee==9.0.4->playwright>=1.18->pytest-playwright) (4.5.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (21.4.0)\n",
      "Requirement already satisfied: iniconfig in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (1.1.1)\n",
      "Requirement already satisfied: packaging in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (21.3)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (1.11.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest<8.0.0,>=6.2.4->pytest-playwright) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.9 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.28.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from python-slugify<9.0.0,>=6.0.0->pytest-playwright) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2022.9.24)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jamesaphoenix/opt/anaconda3/lib/python3.9/site-packages (from packaging->pytest<8.0.0,>=6.2.4->pytest-playwright) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing Playwright:\n",
    "%pip install pytest-playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SERPAPI_API_KEY\"] = \"\"\n",
    "TOPIC = \"What are the disadvantages of using a neural network?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM + text splitter:\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1500, chunk_overlap=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearch(\n",
    "    {\n",
    "        \"q\": TOPIC,\n",
    "        \"location\": \"Austin,Texas\",\n",
    "        \"api_key\": os.environ[\"SERPAPI_API_KEY\"],\n",
    "    }\n",
    ")\n",
    "# Get the results:\n",
    "result = search.get_dict()\n",
    "\n",
    "# Put the results in a Pandas DataFrame:\n",
    "serp_results = pd.DataFrame(result[\"organic_results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_content_from_urls(\n",
    "    df: pd.DataFrame, number_of_urls: int = 3, url_column: str = \"link\"\n",
    ") -> List[Document]:\n",
    "    # Get the HTML content of the first 3 URLs:\n",
    "    urls = df[url_column].values[:number_of_urls].tolist()\n",
    "    # If there is only one URL, convert it to a list:\n",
    "    if isinstance(urls, str):\n",
    "        urls = [urls]\n",
    "    # Check for empty URLs:\n",
    "    urls = [url for url in urls if url != \"\"]\n",
    "\n",
    "    # Check for duplicate URLs:\n",
    "    urls = list(set(urls))\n",
    "\n",
    "    # Throw error if no URLs are found:\n",
    "    if len(urls) == 0:\n",
    "        raise ValueError(\"No URLs found!\")\n",
    "    # loader = AsyncHtmlLoader(urls) # Faster but might not always work.\n",
    "    loader = AsyncChromiumLoader(urls)\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_webpages(documents: List[Document]):\n",
    "    html2text = Html2TextTransformer()\n",
    "    return html2text.transform_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentSummary(BaseModel):\n",
    "    concise_summary: str\n",
    "    writing_style: str\n",
    "    key_points: List[str]\n",
    "    expert_opinions: Optional[List[str]] = None\n",
    "    metadata: Dict[\n",
    "        str, str\n",
    "    ] = None  # This comes natively from the LangChain document loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to summarize the text --> LangChain documents --> Summarize the documents\n",
    "def create_summary_from_text(\n",
    "    document: Document, parser: PydanticOutputParser\n",
    ") -> Union[DocumentSummary, None]:\n",
    "    # Split the parent document into chunks:\n",
    "    split_docs = text_splitter.split_documents([document])\n",
    "\n",
    "    # If there are no documents, return None:\n",
    "    if len(split_docs) == 0:\n",
    "        return None\n",
    "\n",
    "    # Run a refine summarization chain that extracts unique key points and opinions within an article:\n",
    "    prompt_template = \"\"\"Act as a content SEO researcher. You are interested in summarizing and extracting key points from the following text. \n",
    "    The insights gained will be used to do content research and we will compare the key points, insights and summaries across multiple articles.\n",
    "    ---\n",
    "    - You must analyze the text and extract the key points and opinions from the following text\n",
    "    - You must extract the key points and opinions from the following text:\n",
    "    {text}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # Refine template:\n",
    "    refine_template = (\n",
    "        \"Your job is to produce a final summary.\\n\"\n",
    "        \"We have provided an existing summary, key points, and expert opinions up to a certain point: {existing_answer}\\n\"\n",
    "        \"We have the opportunity to refine the existing content (only if needed) with some more context below.\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"{text}\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"Given the new context, refine the original summary.\\n\"\n",
    "        \"If the context isn't useful or does not provide additional key points or expert opinions, you must return the original summary.\"\n",
    "        \"{format_instructions}\"\n",
    "    )\n",
    "    refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "    chain = load_summarize_chain(\n",
    "        llm=llm,\n",
    "        chain_type=\"refine\",\n",
    "        question_prompt=prompt,\n",
    "        refine_prompt=refine_prompt,\n",
    "        return_intermediate_steps=True,\n",
    "        input_key=\"input_documents\",\n",
    "        output_key=\"output_text\",\n",
    "    )\n",
    "    summary_result = chain(\n",
    "        {\n",
    "            \"input_documents\": split_docs,\n",
    "            \"format_instructions\": parser.get_format_instructions(),\n",
    "        },\n",
    "        return_only_outputs=True,\n",
    "    )\n",
    "\n",
    "    # Parsing the output:\n",
    "    document_summary = parser.parse(summary_result[\"output_text\"])\n",
    "    # Adding on the metadata:\n",
    "    document_summary.metadata = document.metadata\n",
    "    return document_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=DocumentSummary)\n",
    "\n",
    "# Extract the html content from the URLs:\n",
    "html_documents = get_html_content_from_urls(serp_results)\n",
    "\n",
    "# Extract the text from the URLs:\n",
    "text_documents = extract_text_from_webpages(html_documents)\n",
    "\n",
    "# Create a customized summary with a refine chain for all docs, use a list comprehension:\n",
    "summaries = [\n",
    "    create_summary_from_text(document, parser)\n",
    "    for document in text_documents\n",
    "    if create_summary_from_text(document, parser) is not None\n",
    "]\n",
    "\n",
    "if len(summaries) == 0:\n",
    "    raise ValueError(\"No summaries were created!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Expert Interview Questions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import HumanInputRun, StructuredTool\n",
    "\n",
    "# def get_input() -> str:\n",
    "#     print(\"Insert your text. Enter 'q' or press Ctrl-D (or Ctrl-Z on Windows) to end.\")\n",
    "#     contents = []\n",
    "#     while True:\n",
    "#         try:\n",
    "#             line = input()\n",
    "#         except EOFError:\n",
    "#             break\n",
    "#         if line == \"q\":\n",
    "#             break\n",
    "#         contents.append(line)\n",
    "#     return \"\\n\".join(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tools:\n",
    "# def generate_a_list_of_interview_questions(\n",
    "#     document_summaries: str\n",
    "# ) -> str:\n",
    "\n",
    "#     # Create an LLM:\n",
    "#     chat = ChatOpenAI(temperature=0.6)\n",
    "\n",
    "#     # Create an output parser:\n",
    "#     class InterviewQuestions(BaseModel):\n",
    "#         questions: List[str] = Field(description='A list of questions interviewing a specific interview expert.')\n",
    "    \n",
    "#     # Set up a parser + inject instructions into the prompt template.\n",
    "#     parser = PydanticOutputParser(pydantic_object=InterviewQuestions)\n",
    "\n",
    "#     # Create a system message:\n",
    "#     system_message = \"\"\"You are a content SEO researcher. Previously you have summarized and extracted key points from SERP results. \n",
    "#     The insights gained will be used to do content research and we will compare the key points, insights and summaries across multiple articles.\n",
    "#     You are now going to interview a content expert. You will ask them questions about the following topic: {topic}.\n",
    "\n",
    "#     You must follow the following rules:\n",
    "#     - Return a list of questions that you would ask a content expert about the topic.\n",
    "#     - You must ask at least 5 questions.\n",
    "#     - You are looking for information gain and unique insights that are not already covered in the {document_summaries} information.\n",
    "#     - You must ask questions that are open-ended and not yes/no questions.\n",
    "#     {format_instructions}\n",
    "#     \"\"\"\n",
    "#     system_prompt = SystemMessagePromptTemplate.from_template(system_message)\n",
    "#     system_message = system_prompt.format(document_summaries=document_summaries, topic=TOPIC, format_instructions=parser.get_format_instructions())\n",
    "#     result = chat([system_message])\n",
    "#     return parser.parse(result.content)\n",
    "\n",
    "\n",
    "# # Create all of the tools:\n",
    "# tools = [StructuredTool.from_function(generate_a_list_of_interview_questions, description=\"\"\"\n",
    "#     Generates a list of open-ended questions to ask a content expert about a given topic.\n",
    "\n",
    "#     Args:\n",
    "#     - document_summaries: a list of DocumentSummary objects containing key points and opinions about the topic.\n",
    "#     - topic: a string representing the topic to ask questions about.\n",
    "\n",
    "#     Returns:\n",
    "#     - A string representing a list of at least 5 open-ended questions to ask a content expert about the topic.\n",
    "\n",
    "#     Raises:\n",
    "#     - ValueError: if no questions are generated.\n",
    "\n",
    "#     Example usage:\n",
    "#     ```\n",
    "#     # create a list of DocumentSummary objects\n",
    "#     summaries = [create_summary_from_text(document, parser) for document in text_documents if create_summary_from_text(document, parser) is not None]\n",
    "\n",
    "#     # generate a list of interview questions\n",
    "#     questions = generate_a_list_of_interview_questions(summaries, \"content marketing\")\n",
    "#     print(questions)\n",
    "#     ```\n",
    "#     \"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory, ReadOnlySharedMemory\n",
    "from langchain.agents import initialize_agent, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain import SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, SystemMessage\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"Complete the objective as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "----\n",
    "\n",
    "Extra information that you have:\n",
    "# Topic: {topic}\n",
    "# Document Summaries: {document_summaries}\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "----\n",
    "Chat History {chat_history}\n",
    "\n",
    "These were previous tasks you completed:\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        # Add the chat history:\n",
    "        print(kwargs)\n",
    "\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [SystemMessage(content=formatted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which tools the agent can use to answer user queries\n",
    "search = SerpAPIWrapper(serpapi_api_key=os.environ['SERPAPI_API_KEY'])\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"topic\", \"document_summaries\", \"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output parser:\n",
    "output_parser = CustomOutputParser()\n",
    "\n",
    "# Make the memory read only:\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "readonlymemory = ReadOnlySharedMemory(memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, \n",
    "                                                    memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "{'topic': 'What are the disadvantages of using a neural network?', 'document_summaries': {'[{\\'concise_summary\\': \\'Neural networks have become popular for modeling complex data, but they have disadvantages.\\', \\'writing_style\\': \\'Informative\\', \\'key_points\\': [\\'Artificial Neural Networks require lots of computational power.\\', \\'Neural network models are hard to explain.\\', \\'Neural network training requires lots of data.\\', \\'Data preparation for neural network models needs careful attention.\\', \\'Optimizing neural network models for production can be challenging.\\'], \\'expert_opinions\\': [], \\'metadata\\': {\\'source\\': \\'https://www.the-analytics.club/disadvantages-of-artificial-neural-networks/\\'}}, {\\'concise_summary\\': \"Neural networks are a form of AI-based learning that can analyze complex data. However, they have several disadvantages, including being a \\'black box\\' and lacking interpretability, taking a long time to develop, requiring lots of data, and being computationally expensive. Despite these downsides, neural networks have advantages such as being able to handle unorganized data, improving accuracy through continuous learning, and increasing flexibility.\", \\'writing_style\\': \\'Informative\\', \\'key_points\\': [\\'Neural networks are a form of AI-based learning designed to analyze complex data\\', \"Disadvantages of neural networks include being a \\'black box\\' and lacking interpretability, taking a long time to develop, requiring lots of data, and being computationally expensive\", \\'Advantages of neural networks include being able to handle unorganized data, improving accuracy through continuous learning, and increasing flexibility\\'], \\'expert_opinions\\': [\\'Neural networks are not always the right choice and may not be suitable for domains where interpretability is critical\\', \\'Developing neural networks can be time-consuming and may not be worth the investment for simpler problems\\', \\'Neural networks usually require large amounts of labeled data, although there are cases where they perform well with less data\\', \\'Neural networks are computationally expensive, especially for deep networks with many layers\\', \\'Neural networks can process large volumes of raw data and improve their performance with more data\\', \\'Neural networks are great for some problems and not so great for others. They are a little over-hyped at the moment, but still useful\\', \\'We need more people who bridge the gap between understanding the theory behind machine learning and the business side\\'], \\'metadata\\': {\\'source\\': \\'https://builtin.com/data-science/disadvantages-neural-networks\\'}}]'}, 'input': 'My name is James Phoenix, what is your name?', 'agent_scratchpad': '', 'tools': 'Search: useful for when you need to answer questions about current events', 'tool_names': 'Search'}\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [0ms] Chain run errored with error:\n",
      "\u001b[0m\"KeyError('chat_history')\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [1ms] Chain run errored with error:\n",
      "\u001b[0m\"KeyError('chat_history')\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'chat_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_y/20jl658s4jl0zvy5c0x0c5140000gn/T/ipykernel_12894/3774378536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTOPIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_summaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'''My name is James Phoenix, what is your name?'''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             ]\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             outputs = (\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1037\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             output = self.agent.plan(\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mAction\u001b[0m \u001b[0mspecifying\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0mtool\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m--> 352\u001b[0;31m         output = self.llm_chain.run(\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             ]\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             outputs = (\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m     98\u001b[0m     ) -> LLMResult:\n\u001b[1;32m     99\u001b[0m         \u001b[0;34m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         return self.llm.generate_prompt(\n\u001b[1;32m    102\u001b[0m             \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mprep_prompts\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mselected_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_variables\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mselected_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0m_colored_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_colored_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"green\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0m_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Prompt after formatting:\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_colored_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/prompts/chat.py\u001b[0m in \u001b[0;36mformat_prompt\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mPromptValue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \"\"\"\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mChatPromptValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_y/20jl658s4jl0zvy5c0x0c5140000gn/T/ipykernel_12894/2125916314.py\u001b[0m in \u001b[0;36mformat_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mformatted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSystemMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'chat_history'"
     ]
    }
   ],
   "source": [
    "agent_executor.run(topic=TOPIC, document_summaries={str([summary.dict() for summary in summaries])}, input='''My name is James Phoenix, what is your name?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a custom LLMChain with memory:\n",
    "# prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "# suffix = \"\"\"Begin!\"\n",
    "\n",
    "# {chat_history}\n",
    "# Topic: {topic}\n",
    "# Document Summaries: {document_summaries}\n",
    "# Task: {task}\n",
    "# {agent_scratchpad}\"\"\"\n",
    "\n",
    "# prompt = ZeroShotAgent.create_prompt(\n",
    "#     tools,\n",
    "#     prefix=prefix,\n",
    "#     suffix=suffix,\n",
    "#     input_variables=[\"topic\", \"document_summaries\", \"task\" ,\"chat_history\", \"agent_scratchpad\"],\n",
    "# )\n",
    "\n",
    "# # Attach the custom LLMChain to an agent:\n",
    "# llm_chain = LLMChain(llm=ChatOpenAI(temperature=0), prompt=prompt)\n",
    "# agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "# agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "#     agent=agent, tools=tools, verbose=True, memory=readonlymemory\n",
    "# )\n",
    "\n",
    "# agent_chain.run(topic=TOPIC, document_summaries={str([summary.dict() for summary in summaries])}, task='''\n",
    "#                 You are to act as an interviewer, and are interviewing an expert.  \n",
    "#                 Given the following Document Summaries from other articles you will need to return 5 question and answers that are answered as part of an interview.\n",
    "#                 ''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## General Article Outline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Article Text Generation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Re-write the Article:\n",
    "\n",
    "- Read this - https://blog.langchain.dev/using-langsmith-to-support-fine-tuning-of-open-source-llms/\n",
    "- Use this? https://github.com/langchain-ai/twitter-finetune/tree/main\n",
    "- Use chat loaders -> https://python.langchain.com/docs/integrations/chat_loaders/?ref=blog.langchain.dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Title Tag Optimization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Interface (use Mike's to do this):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
